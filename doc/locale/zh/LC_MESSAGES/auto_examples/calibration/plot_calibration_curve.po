# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../auto_examples/calibration/plot_calibration_curve.rst:8
msgid "Probability Calibration curves"
msgstr ""

#: ../../auto_examples/calibration/plot_calibration_curve.rst:10
msgid ""
"When performing classification one often wants to predict not only the "
"class label, but also the associated probability. This probability gives "
"some kind of confidence on the prediction. This example demonstrates how "
"to display how well calibrated the predicted probabilities are and how to"
" calibrate an uncalibrated classifier."
msgstr ""

#: ../../auto_examples/calibration/plot_calibration_curve.rst:16
msgid ""
"The experiment is performed on an artificial dataset for binary "
"classification with 100.000 samples (1.000 of them are used for model "
"fitting) with 20 features. Of the 20 features, only 2 are informative and"
" 10 are redundant. The first figure shows the estimated probabilities "
"obtained with logistic regression, Gaussian naive Bayes, and Gaussian "
"naive Bayes with both isotonic calibration and sigmoid calibration. The "
"calibration performance is evaluated with Brier score, reported in the "
"legend (the smaller the better). One can observe here that logistic "
"regression is well calibrated while raw Gaussian naive Bayes performs "
"very badly. This is because of the redundant features which violate the "
"assumption of feature-independence and result in an overly confident "
"classifier, which is indicated by the typical transposed-sigmoid curve."
msgstr ""

#: ../../auto_examples/calibration/plot_calibration_curve.rst:29
msgid ""
"Calibration of the probabilities of Gaussian naive Bayes with isotonic "
"regression can fix this issue as can be seen from the nearly diagonal "
"calibration curve. Sigmoid calibration also improves the brier score "
"slightly, albeit not as strongly as the non-parametric isotonic "
"regression. This can be attributed to the fact that we have plenty of "
"calibration data such that the greater flexibility of the non-parametric "
"model can be exploited."
msgstr ""

#: ../../auto_examples/calibration/plot_calibration_curve.rst:36
msgid ""
"The second figure shows the calibration curve of a linear support-vector "
"classifier (LinearSVC). LinearSVC shows the opposite behavior as Gaussian"
" naive Bayes: the calibration curve has a sigmoid curve, which is typical"
" for an under-confident classifier. In the case of LinearSVC, this is "
"caused by the margin property of the hinge loss, which lets the model "
"focus on hard samples that are close to the decision boundary (the "
"support vectors)."
msgstr ""

#: ../../auto_examples/calibration/plot_calibration_curve.rst:43
msgid ""
"Both kinds of calibration can fix this issue and yield nearly identical "
"results. This shows that sigmoid calibration can deal with situations "
"where the calibration curve of the base classifier is sigmoid (e.g., for "
"LinearSVC) but not where it is transposed-sigmoid (e.g., Gaussian naive "
"Bayes)."
msgstr ""

#: ../../auto_examples/calibration/plot_calibration_curve.rst:64
msgid "**Script output**::"
msgstr ""

#: ../../auto_examples/calibration/plot_calibration_curve.rst:116
msgid ""
"**Python source code:** :download:`plot_calibration_curve.py "
"<plot_calibration_curve.py>`"
msgstr ""

#: ../../auto_examples/calibration/plot_calibration_curve.rst:121
msgid ""
"**Total running time of the example:**  5.31 seconds ( 0 minutes  5.31 "
"seconds)"
msgstr ""

