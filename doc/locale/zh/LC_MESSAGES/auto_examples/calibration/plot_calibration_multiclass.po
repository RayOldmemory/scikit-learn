# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../auto_examples/calibration/plot_calibration_multiclass.rst:8
msgid "Probability Calibration for 3-class classification"
msgstr ""

#: ../../auto_examples/calibration/plot_calibration_multiclass.rst:10
msgid ""
"This example illustrates how sigmoid calibration changes predicted "
"probabilities for a 3-class classification problem. Illustrated is the "
"standard 2-simplex, where the three corners correspond to the three "
"classes. Arrows point from the probability vectors predicted by an "
"uncalibrated classifier to the probability vectors predicted by the same "
"classifier after sigmoid calibration on a hold-out validation set. Colors"
" indicate the true class of an instance (red: class 1, green: class 2, "
"blue: class 3)."
msgstr ""

#: ../../auto_examples/calibration/plot_calibration_multiclass.rst:18
msgid ""
"The base classifier is a random forest classifier with 25 base estimators"
" (trees). If this classifier is trained on all 800 training datapoints, "
"it is overly confident in its predictions and thus incurs a large log-"
"loss. Calibrating an identical classifier, which was trained on 600 "
"datapoints, with method='sigmoid' on the remaining 200 datapoints reduces"
" the confidence of the predictions, i.e., moves the probability vectors "
"from the edges of the simplex towards the center. This calibration "
"results in a lower log-loss. Note that an alternative would have been to "
"increase the number of base estimators which would have resulted in a "
"similar decrease in log-loss."
msgstr ""

#: ../../auto_examples/calibration/plot_calibration_multiclass.rst:44
msgid "**Script output**::"
msgstr ""

#: ../../auto_examples/calibration/plot_calibration_multiclass.rst:52
msgid ""
"**Python source code:** :download:`plot_calibration_multiclass.py "
"<plot_calibration_multiclass.py>`"
msgstr ""

#: ../../auto_examples/calibration/plot_calibration_multiclass.rst:57
msgid ""
"**Total running time of the example:**  1.40 seconds ( 0 minutes  1.40 "
"seconds)"
msgstr ""

