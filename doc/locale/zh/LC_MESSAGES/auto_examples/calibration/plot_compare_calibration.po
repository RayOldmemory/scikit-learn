# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../auto_examples/calibration/plot_compare_calibration.rst:8
msgid "Comparison of Calibration of Classifiers"
msgstr ""

#: ../../auto_examples/calibration/plot_compare_calibration.rst:10
msgid ""
"Well calibrated classifiers are probabilistic classifiers for which the "
"output of the predict_proba method can be directly interpreted as a "
"confidence level. For instance a well calibrated (binary) classifier "
"should classify the samples such that among the samples to which it gave "
"a predict_proba value close to 0.8, approx. 80% actually belong to the "
"positive class."
msgstr ""

#: ../../auto_examples/calibration/plot_compare_calibration.rst:16
msgid ""
"LogisticRegression returns well calibrated predictions as it directly "
"optimizes log-loss. In contrast, the other methods return biased "
"probilities, with different biases per method:"
msgstr ""

#: ../../auto_examples/calibration/plot_compare_calibration.rst:20
msgid ""
"GaussianNaiveBayes tends to push probabilties to 0 or 1 (note the counts "
"in the histograms). This is mainly because it makes the assumption that "
"features are conditionally independent given the class, which is not the "
"case in this dataset which contains 2 redundant features."
msgstr ""

#: ../../auto_examples/calibration/plot_compare_calibration.rst:25
msgid ""
"RandomForestClassifier shows the opposite behavior: the histograms show "
"peaks at approx. 0.2 and 0.9 probability, while probabilities close to 0 "
"or 1 are very rare. An explanation for this is given by Niculescu-Mizil "
"and Caruana [1]: \"Methods such as bagging and random forests that "
"average predictions from a base set of models can have difficulty making "
"predictions near 0 and 1 because variance in the underlying base models "
"will bias predictions that should be near zero or one away from these "
"values. Because predictions are restricted to the interval [0,1], errors "
"caused by variance tend to be one- sided near zero and one. For example, "
"if a model should predict p = 0 for a case, the only way bagging can "
"achieve this is if all bagged trees predict zero. If we add noise to the "
"trees that bagging is averaging over, this noise will cause some trees to"
" predict values larger than 0 for this case, thus moving the average "
"prediction of the bagged ensemble away from 0. We observe this effect "
"most strongly with random forests because the base-level trees trained "
"with random forests have relatively high variance due to feature "
"subseting.\" As a result, the calibration curve shows a characteristic "
"sigmoid shape, indicating that the classifier could trust its "
"\"intuition\" more and return probabilties closer to 0 or 1 typically."
msgstr ""

#: ../../auto_examples/calibration/plot_compare_calibration.rst:44
msgid ""
"Support Vector Classification (SVC) shows an even more sigmoid curve as "
"the  RandomForestClassifier, which is typical for maximum-margin methods "
"(compare Niculescu-Mizil and Caruana [1]), which focus on hard samples "
"that are close to the decision boundary (the support vectors)."
msgstr ""

#: ../../auto_examples/calibration/plot_compare_calibration.rst
msgid "References:"
msgstr ""

#: ../../auto_examples/calibration/plot_compare_calibration.rst:51
msgid ""
"Predicting Good Probabilities with Supervised Learning, A. Niculescu-"
"Mizil & R. Caruana, ICML 2005"
msgstr ""

#: ../../auto_examples/calibration/plot_compare_calibration.rst:62
msgid ""
"**Python source code:** :download:`plot_compare_calibration.py "
"<plot_compare_calibration.py>`"
msgstr ""

#: ../../auto_examples/calibration/plot_compare_calibration.rst:67
msgid ""
"**Total running time of the example:**  2.70 seconds ( 0 minutes  2.70 "
"seconds)"
msgstr ""

