# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../auto_examples/linear_model/plot_logistic_l1_l2_sparsity.rst:8
msgid "L1 Penalty and Sparsity in Logistic Regression"
msgstr ""

#: ../../auto_examples/linear_model/plot_logistic_l1_l2_sparsity.rst:10
msgid ""
"Comparison of the sparsity (percentage of zero coefficients) of solutions"
" when L1 and L2 penalty are used for different values of C. We can see "
"that large values of C give more freedom to the model.  Conversely, "
"smaller values of C constrain the model more. In the L1 penalty case, "
"this leads to sparser solutions."
msgstr ""

#: ../../auto_examples/linear_model/plot_logistic_l1_l2_sparsity.rst:16
msgid ""
"We classify 8x8 images of digits into two classes: 0-4 against 5-9. The "
"visualization shows coefficients of the models for varying C."
msgstr ""

#: ../../auto_examples/linear_model/plot_logistic_l1_l2_sparsity.rst:25
msgid "**Script output**::"
msgstr ""

#: ../../auto_examples/linear_model/plot_logistic_l1_l2_sparsity.rst:45
msgid ""
"**Python source code:** :download:`plot_logistic_l1_l2_sparsity.py "
"<plot_logistic_l1_l2_sparsity.py>`"
msgstr ""

#: ../../auto_examples/linear_model/plot_logistic_l1_l2_sparsity.rst:50
msgid ""
"**Total running time of the example:**  1.01 seconds ( 0 minutes  1.01 "
"seconds)"
msgstr ""

