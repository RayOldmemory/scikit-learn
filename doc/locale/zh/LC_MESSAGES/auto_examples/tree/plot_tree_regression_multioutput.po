# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../auto_examples/tree/plot_tree_regression_multioutput.rst:8
msgid "Multi-output Decision Tree Regression"
msgstr ""

#: ../../auto_examples/tree/plot_tree_regression_multioutput.rst:10
msgid "An example to illustrate multi-output regression with decision tree."
msgstr ""

#: ../../auto_examples/tree/plot_tree_regression_multioutput.rst:12
msgid ""
"The :ref:`decision trees <tree>` is used to predict simultaneously the "
"noisy x and y observations of a circle given a single underlying feature."
" As a result, it learns local linear regressions approximating the "
"circle."
msgstr ""

#: ../../auto_examples/tree/plot_tree_regression_multioutput.rst:17
msgid ""
"We can see that if the maximum depth of the tree (controlled by the "
"`max_depth` parameter) is set too high, the decision trees learn too fine"
" details of the training data and learn from the noise, i.e. they "
"overfit."
msgstr ""

#: ../../auto_examples/tree/plot_tree_regression_multioutput.rst:29
msgid ""
"**Python source code:** :download:`plot_tree_regression_multioutput.py "
"<plot_tree_regression_multioutput.py>`"
msgstr ""

#: ../../auto_examples/tree/plot_tree_regression_multioutput.rst:34
msgid ""
"**Total running time of the example:**  0.60 seconds ( 0 minutes  0.60 "
"seconds)"
msgstr ""

