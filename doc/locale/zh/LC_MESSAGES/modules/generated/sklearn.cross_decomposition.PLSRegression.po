# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.cross_decomposition.PLSRegression.rst:2
msgid ":mod:`sklearn.cross_decomposition`.PLSRegression"
msgstr ""

#: :3
msgid "PLS regression"
msgstr ""

#: :5
msgid ""
"PLSRegression implements the PLS 2 blocks regression known as PLS2 or "
"PLS1 in case of one dimensional response. This class inherits from _PLS "
"with mode=\"A\", deflation_mode=\"regression\", norm_y_weights=False and "
"algorithm=\"nipals\"."
msgstr ""

#: :10
msgid "Read more in the :ref:`User Guide <cross_decomposition>`."
msgstr ""

#: :14
msgid "**n_components** : int, (default 2)"
msgstr ""

#: :16
msgid "Number of components to keep."
msgstr ""

#: :18
msgid "**scale** : boolean, (default True)"
msgstr ""

#: :20
msgid "whether to scale the data"
msgstr ""

#: :22
msgid "**max_iter** : an integer, (default 500)"
msgstr ""

#: :24
msgid ""
"the maximum number of iterations of the NIPALS inner loop (used only if "
"algorithm=\"nipals\")"
msgstr ""

#: :27
msgid "**tol** : non-negative real"
msgstr ""

#: :29
msgid "Tolerance used in the iterative algorithm default 1e-06."
msgstr ""

#: :31 :17 :12
msgid "**copy** : boolean, default True"
msgstr ""

#: :33
msgid ""
"Whether the deflation should be done on a copy. Let the default value to "
"True unless you don't care about side effect"
msgstr ""

#: :38
msgid "**x_weights_** : array, [p, n_components]"
msgstr ""

#: :40
msgid "X block weights vectors."
msgstr ""

#: :42
msgid "**y_weights_** : array, [q, n_components]"
msgstr ""

#: :44
msgid "Y block weights vectors."
msgstr ""

#: :46
msgid "**x_loadings_** : array, [p, n_components]"
msgstr ""

#: :48
msgid "X block loadings vectors."
msgstr ""

#: :50
msgid "**y_loadings_** : array, [q, n_components]"
msgstr ""

#: :52
msgid "Y block loadings vectors."
msgstr ""

#: :54
msgid "**x_scores_** : array, [n_samples, n_components]"
msgstr ""

#: :56
msgid "X scores."
msgstr ""

#: :58
msgid "**y_scores_** : array, [n_samples, n_components]"
msgstr ""

#: :60
msgid "Y scores."
msgstr ""

#: :62
msgid "**x_rotations_** : array, [p, n_components]"
msgstr ""

#: :64
msgid "X block to latents rotations."
msgstr ""

#: :66
msgid "**y_rotations_** : array, [q, n_components]"
msgstr ""

#: :68
msgid "Y block to latents rotations."
msgstr ""

#: :70
msgid "**coef_: array, [p, q]** :"
msgstr ""

#: :72
msgid "The coefficients of the linear model: ``Y = X coef_ + Err``"
msgstr ""

#: :74
msgid "**n_iter_** : array-like"
msgstr ""

#: :76
msgid "Number of iterations of the NIPALS inner loop for each component."
msgstr ""

#: :80 :17
msgid "Notes"
msgstr ""

#: :81
msgid "Matrices::"
msgstr ""

#: :90
msgid "Are computed such that::"
msgstr ""

#: :98
msgid "where Xk and Yk are residual matrices at iteration k."
msgstr ""

#: :100
msgid ""
"`Slides explaining PLS "
"<http://www.eigenvector.com/Docs/Wise_pls_properties.pdf>`"
msgstr ""

#: :102
msgid ""
"For each component k, find weights u, v that optimizes: ``max corr(Xk u, "
"Yk v) * std(Xk u) std(Yk u)``, such that ``|u| = 1``"
msgstr ""

#: :105
msgid ""
"Note that it maximizes both the correlations between the scores and the "
"intra-block variances."
msgstr ""

#: :108
msgid ""
"The residual matrix of X (Xk+1) block is obtained by the deflation on the"
" current X score: x_score."
msgstr ""

#: :111
msgid ""
"The residual matrix of Y (Yk+1) block is obtained by deflation on the "
"current X score. This performs the PLS regression known as PLS2. This "
"mode is prediction oriented."
msgstr ""

#: :115
msgid ""
"This implementation provides the same results that 3 PLS packages "
"provided in the R language (R-project):"
msgstr ""

#: :118
msgid "\"mixOmics\" with function pls(X, Y, mode = \"regression\")"
msgstr ""

#: :119
msgid "\"plspm \" with function plsreg2(X, Y)"
msgstr ""

#: :120
msgid "\"pls\" with function oscorespls.fit(X, Y)"
msgstr ""

#: :123
msgid "References"
msgstr ""

#: :124
msgid ""
"Jacob A. Wegelin. A survey of Partial Least Squares (PLS) methods, with "
"emphasis on the two-block case. Technical Report 371, Department of "
"Statistics, University of Washington, Seattle, 2000."
msgstr ""

#: :128
msgid ""
"In french but still a reference: Tenenhaus, M. (1998). La regression PLS:"
" theorie et pratique. Paris: Editions Technic."
msgstr ""

#: :135
msgid "Examples"
msgstr ""

#: :147
msgid "Methods"
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`fit <sklearn.cross_decomposition.PLSRegression.fit>`\\ (X, Y)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Fit model to data."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`fit_transform "
"<sklearn.cross_decomposition.PLSRegression.fit_transform>`\\ (X[, y])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Learn and apply the dimension reduction on the train data."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`get_params "
"<sklearn.cross_decomposition.PLSRegression.get_params>`\\ ([deep])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Get parameters for this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`predict <sklearn.cross_decomposition.PLSRegression.predict>`\\ (X[,"
" copy])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Apply the dimension reduction learned on the train data."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`score <sklearn.cross_decomposition.PLSRegression.score>`\\ (X, y[, "
"sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Returns the coefficient of determination R^2 of the prediction."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`set_params "
"<sklearn.cross_decomposition.PLSRegression.set_params>`\\ (\\*\\*params)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Set the parameters of this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`transform <sklearn.cross_decomposition.PLSRegression.transform>`\\ "
"(X[, Y, copy])"
msgstr ""

#: :7
msgid "**X** : array-like, shape = [n_samples, n_features]"
msgstr ""

#: :9
msgid ""
"Training vectors, where n_samples in the number of samples and n_features"
" is the number of predictors."
msgstr ""

#: :12
msgid "**Y** : array-like of response, shape = [n_samples, n_targets]"
msgstr ""

#: :14
msgid ""
"Target vectors, where n_samples in the number of samples and n_targets is"
" the number of response variables."
msgstr ""

#: :7
msgid "**X** : array-like of predictors, shape = [n_samples, p]"
msgstr ""

#: :9
msgid ""
"Training vectors, where n_samples in the number of samples and p is the "
"number of predictors."
msgstr ""

#: :12
msgid "**Y** : array-like of response, shape = [n_samples, q], optional"
msgstr ""

#: :14
msgid ""
"Training vectors, where n_samples in the number of samples and q is the "
"number of response variables."
msgstr ""

#: :19 :14
msgid "Whether to copy X and Y, or perform in-place normalization."
msgstr ""

#: :23
msgid "**x_scores if Y is not given, (x_scores, y_scores) otherwise.** :"
msgstr ""

#: :7
msgid "**deep: boolean, optional** :"
msgstr ""

#: :9
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: :14
msgid "**params** : mapping of string to any"
msgstr ""

#: :16
msgid "Parameter names mapped to their values."
msgstr ""

#: :18
msgid ""
"This call requires the estimation of a p x q matrix, which may be an "
"issue in high dimensional space."
msgstr ""

#: :5
msgid ""
"The coefficient R^2 is defined as (1 - u/v), where u is the regression "
"sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual sum "
"of squares ((y_true - y_true.mean()) ** 2).sum(). Best possible score is "
"1.0 and it can be negative (because the model can be arbitrarily worse). "
"A constant model that always predicts the expected value of y, "
"disregarding the input features, would get a R^2 score of 0.0."
msgstr ""

#: :15
msgid "**X** : array-like, shape = (n_samples, n_features)"
msgstr ""

#: :17
msgid "Test samples."
msgstr ""

#: :19
msgid "**y** : array-like, shape = (n_samples) or (n_samples, n_outputs)"
msgstr ""

#: :21
msgid "True values for X."
msgstr ""

#: :23
msgid "**sample_weight** : array-like, shape = [n_samples], optional"
msgstr ""

#: :25
msgid "Sample weights."
msgstr ""

#: :29
msgid "**score** : float"
msgstr ""

#: :31
msgid "R^2 of self.predict(X) wrt. y."
msgstr ""

#: :5
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as pipelines). The former have parameters of the form "
"``<component>__<parameter>`` so that it's possible to update each "
"component of a nested object."
msgstr ""

#: :12
msgid "**self** :"
msgstr ""

#: ../../modules/generated/sklearn.cross_decomposition.PLSRegression.examples:3
msgid "Examples using ``sklearn.cross_decomposition.PLSRegression``"
msgstr ""

#: ../../modules/generated/sklearn.cross_decomposition.PLSRegression.examples:25
msgid ":ref:`example_cross_decomposition_plot_compare_cross_decomposition.py`"
msgstr ""

