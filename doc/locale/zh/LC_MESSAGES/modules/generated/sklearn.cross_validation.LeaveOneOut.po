# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.cross_validation.LeaveOneOut.rst:2
msgid ":mod:`sklearn.cross_validation`.LeaveOneOut"
msgstr ""

#: :3
msgid "Leave-One-Out cross validation iterator."
msgstr ""

#: :5
msgid ""
"Provides train/test indices to split data in train test sets. Each sample"
" is used once as a test set (singleton) while the remaining samples form "
"the training set."
msgstr ""

#: :9
msgid ""
"Note: ``LeaveOneOut(n)`` is equivalent to ``KFold(n, n_folds=n)`` and "
"``LeavePOut(n, p=1)``."
msgstr ""

#: :12
msgid ""
"Due to the high number of test sets (which is the same as the number of "
"samples) this cross validation method can be very costly. For large "
"datasets one should favor KFold, StratifiedKFold or ShuffleSplit."
msgstr ""

#: :17
msgid "Read more in the :ref:`User Guide <cross_validation>`."
msgstr ""

#: :21
msgid "**n** : int"
msgstr ""

#: :23
msgid "Total number of elements in dataset."
msgstr ""

#: :27
msgid ":obj:`LeaveOneLabelOut`, :obj:`domain-specific`"
msgstr ""

#: :30
msgid "Examples"
msgstr ""

