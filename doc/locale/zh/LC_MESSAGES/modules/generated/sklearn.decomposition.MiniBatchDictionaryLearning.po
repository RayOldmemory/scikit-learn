# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.decomposition.MiniBatchDictionaryLearning.rst:2
msgid ":mod:`sklearn.decomposition`.MiniBatchDictionaryLearning"
msgstr ""

#: :3
msgid "Mini-batch dictionary learning"
msgstr ""

#: :5
msgid ""
"Finds a dictionary (a set of atoms) that can best be used to represent "
"data using a sparse code."
msgstr ""

#: :8
msgid "Solves the optimization problem::"
msgstr ""

#: :14
msgid "Read more in the :ref:`User Guide <DictionaryLearning>`."
msgstr ""

#: :18
msgid "**n_components** : int,"
msgstr ""

#: :20
msgid "number of dictionary elements to extract"
msgstr ""

#: :22
msgid "**alpha** : float,"
msgstr ""

#: :24
msgid "sparsity controlling parameter"
msgstr ""

#: :26
msgid "**n_iter** : int,"
msgstr ""

#: :28
msgid "total number of iterations to perform"
msgstr ""

#: :30
msgid "**fit_algorithm** : {'lars', 'cd'}"
msgstr ""

#: :32
msgid ""
"lars: uses the least angle regression method to solve the lasso problem "
"(linear_model.lars_path) cd: uses the coordinate descent method to "
"compute the Lasso solution (linear_model.Lasso). Lars will be faster if "
"the estimated components are sparse."
msgstr ""

#: :38
msgid ""
"**transform_algorithm** : {'lasso_lars', 'lasso_cd', 'lars', 'omp',     "
"'threshold'}"
msgstr ""

#: :40
msgid ""
"Algorithm used to transform the data. lars: uses the least angle "
"regression method (linear_model.lars_path) lasso_lars: uses Lars to "
"compute the Lasso solution lasso_cd: uses the coordinate descent method "
"to compute the Lasso solution (linear_model.Lasso). lasso_lars will be "
"faster if the estimated components are sparse. omp: uses orthogonal "
"matching pursuit to estimate the sparse solution threshold: squashes to "
"zero all coefficients less than alpha from the projection dictionary * X'"
msgstr ""

#: :50
msgid "**transform_n_nonzero_coefs** : int, ``0.1 * n_features`` by default"
msgstr ""

#: :52
msgid ""
"Number of nonzero coefficients to target in each column of the solution. "
"This is only used by `algorithm='lars'` and `algorithm='omp'` and is "
"overridden by `alpha` in the `omp` case."
msgstr ""

#: :56
msgid "**transform_alpha** : float, 1. by default"
msgstr ""

#: :58
msgid ""
"If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`, `alpha` is the "
"penalty applied to the L1 norm. If `algorithm='threshold'`, `alpha` is "
"the absolute value of the threshold below which coefficients will be "
"squashed to zero. If `algorithm='omp'`, `alpha` is the tolerance "
"parameter: the value of the reconstruction error targeted. In this case, "
"it overrides `n_nonzero_coefs`."
msgstr ""

#: :66
msgid "**split_sign** : bool, False by default"
msgstr ""

#: :68
msgid ""
"Whether to split the sparse feature vector into the concatenation of its "
"negative part and its positive part. This can improve the performance of "
"downstream classifiers."
msgstr ""

#: :72
msgid "**n_jobs** : int,"
msgstr ""

#: :74
msgid "number of parallel jobs to run"
msgstr ""

#: :76
msgid "**dict_init** : array of shape (n_components, n_features),"
msgstr ""

#: :78
msgid "initial value of the dictionary for warm restart scenarios"
msgstr ""

#: :80
msgid "**verbose :** :"
msgstr ""

#: :82
msgid "degree of verbosity of the printed output"
msgstr ""

#: :84
msgid "**batch_size** : int,"
msgstr ""

#: :86
msgid "number of samples in each mini-batch"
msgstr ""

#: :88
msgid "**shuffle** : bool,"
msgstr ""

#: :90
msgid "whether to shuffle the samples before forming batches"
msgstr ""

#: :92
msgid "**random_state** : int or RandomState"
msgstr ""

#: :94
msgid "Pseudo number generator state used for random sampling."
msgstr ""

#: :98
msgid "**components_** : array, [n_components, n_features]"
msgstr ""

#: :100
msgid "components extracted from the data"
msgstr ""

#: :102
msgid "**inner_stats_** : tuple of (A, B) ndarrays"
msgstr ""

#: :104
msgid ""
"Internal sufficient statistics that are kept by the algorithm. Keeping "
"them is useful in online settings, to avoid loosing the history of the "
"evolution, but they shouldn't have any use for the end user. A "
"(n_components, n_components) is the dictionary covariance matrix. B "
"(n_features, n_components) is the data approximation matrix"
msgstr ""

#: :111
msgid "**n_iter_** : int"
msgstr ""

#: :113
msgid "Number of iterations run."
msgstr ""

#: :117
msgid ""
":obj:`SparseCoder`, :obj:`DictionaryLearning`, :obj:`SparsePCA`, "
":obj:`MiniBatchSparsePCA`"
msgstr ""

#: :120
msgid "Notes"
msgstr ""

#: :121
msgid "**References:**"
msgstr ""

#: :123
msgid ""
"J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning"
" for sparse coding (http://www.di.ens.fr/sierra/pdfs/icml09.pdf)"
msgstr ""

#: :127
msgid "Methods"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`fit <sklearn.decomposition.MiniBatchDictionaryLearning.fit>`\\ (X[,"
" y])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Fit the model from data in X."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`fit_transform "
"<sklearn.decomposition.MiniBatchDictionaryLearning.fit_transform>`\\ (X[,"
" y])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Fit to data, then transform it."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`get_params "
"<sklearn.decomposition.MiniBatchDictionaryLearning.get_params>`\\ "
"([deep])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Get parameters for this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`partial_fit "
"<sklearn.decomposition.MiniBatchDictionaryLearning.partial_fit>`\\ (X[, "
"y, iter_offset])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Updates the model using the data in X as a mini-batch."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`set_params "
"<sklearn.decomposition.MiniBatchDictionaryLearning.set_params>`\\ "
"(\\*\\*params)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Set the parameters of this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`transform "
"<sklearn.decomposition.MiniBatchDictionaryLearning.transform>`\\ (X[, y])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Encode the data as a sparse combination of the dictionary atoms."
msgstr ""

#: :7
msgid "**X: array-like, shape (n_samples, n_features)** :"
msgstr ""

#: :9
msgid ""
"Training vector, where n_samples in the number of samples and n_features "
"is the number of features."
msgstr ""

#: :14 :21
msgid "**self** : object"
msgstr ""

#: :16 :23
msgid "Returns the instance itself."
msgstr ""

#: :5
msgid ""
"Fits transformer to X and y with optional parameters fit_params and "
"returns a transformed version of X."
msgstr ""

#: :10
msgid "**X** : numpy array of shape [n_samples, n_features]"
msgstr ""

#: :12
msgid "Training set."
msgstr ""

#: :14
msgid "**y** : numpy array of shape [n_samples]"
msgstr ""

#: :16
msgid "Target values."
msgstr ""

#: :20
msgid "**X_new** : numpy array of shape [n_samples, n_features_new]"
msgstr ""

#: :22
msgid "Transformed array."
msgstr ""

#: :7
msgid "**deep: boolean, optional** :"
msgstr ""

#: :9
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: :14
msgid "**params** : mapping of string to any"
msgstr ""

#: :16
msgid "Parameter names mapped to their values."
msgstr ""

#: :12
msgid "**iter_offset: integer, optional** :"
msgstr ""

#: :14
msgid ""
"The number of iteration on data batches that has been performed before "
"this call to partial_fit. This is optional: if no number is passed, the "
"memory of the object is used."
msgstr ""

#: :5
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as pipelines). The former have parameters of the form "
"``<component>__<parameter>`` so that it's possible to update each "
"component of a nested object."
msgstr ""

#: :12
msgid "**self** :"
msgstr ""

#: :5
msgid "Coding method is determined by the object parameter `transform_algorithm`."
msgstr ""

#: :10
msgid "**X** : array of shape (n_samples, n_features)"
msgstr ""

#: :12
msgid ""
"Test data to be transformed, must have the same number of features as the"
" data used to train the model."
msgstr ""

#: :17
msgid "**X_new** : array, shape (n_samples, n_components)"
msgstr ""

#: :19
msgid "Transformed data"
msgstr ""

#: ../../modules/generated/sklearn.decomposition.MiniBatchDictionaryLearning.examples:3
msgid "Examples using ``sklearn.decomposition.MiniBatchDictionaryLearning``"
msgstr ""

#: ../../modules/generated/sklearn.decomposition.MiniBatchDictionaryLearning.examples:25
msgid ":ref:`example_decomposition_plot_faces_decomposition.py`"
msgstr ""

#: ../../modules/generated/sklearn.decomposition.MiniBatchDictionaryLearning.examples:45
msgid ":ref:`example_decomposition_plot_image_denoising.py`"
msgstr ""

