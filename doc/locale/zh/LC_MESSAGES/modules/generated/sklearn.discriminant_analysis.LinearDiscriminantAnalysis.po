# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.rst:2
msgid ":mod:`sklearn.discriminant_analysis`.LinearDiscriminantAnalysis"
msgstr ""

#: :3
msgid "Linear Discriminant Analysis"
msgstr ""

#: :5
msgid ""
"A classifier with a linear decision boundary, generated by fitting class "
"conditional densities to the data and using Bayes' rule."
msgstr ""

#: :8
msgid ""
"The model fits a Gaussian density to each class, assuming that all "
"classes share the same covariance matrix."
msgstr ""

#: :11
msgid ""
"The fitted model can also be used to reduce the dimensionality of the "
"input by projecting it to the most discriminative directions."
msgstr ""

#: :14
msgid "*LinearDiscriminantAnalysis*."
msgstr ""

#: :17
msgid ""
"Deprecated :class:`lda.LDA` have been moved to "
"*LinearDiscriminantAnalysis*."
msgstr ""

#: :22
msgid "**solver** : string, optional"
msgstr ""

#: :29
msgid "Solver to use, possible values:"
msgstr ""

#: :26
msgid "'svd': Singular value decomposition (default). Does not compute the"
msgstr ""

#: :26
msgid ""
"covariance matrix, therefore this solver is recommended for data with a "
"large number of features."
msgstr ""

#: :28
msgid "'lsqr': Least squares solution, can be combined with shrinkage."
msgstr ""

#: :29
msgid "'eigen': Eigenvalue decomposition, can be combined with shrinkage."
msgstr ""

#: :31
msgid "**shrinkage** : string or float, optional"
msgstr ""

#: :36
msgid "Shrinkage parameter, possible values:"
msgstr ""

#: :34
msgid "None: no shrinkage (default)."
msgstr ""

#: :35
msgid "'auto': automatic shrinkage using the Ledoit-Wolf lemma."
msgstr ""

#: :36
msgid "float between 0 and 1: fixed shrinkage parameter."
msgstr ""

#: :38
msgid "Note that shrinkage works only with 'lsqr' and 'eigen' solvers."
msgstr ""

#: :40
msgid "**priors** : array, optional, shape (n_classes,)"
msgstr ""

#: :42
msgid "Class priors."
msgstr ""

#: :44
msgid "**n_components** : int, optional"
msgstr ""

#: :46
msgid "Number of components (< n_classes - 1) for dimensionality reduction."
msgstr ""

#: :48
msgid "**store_covariance** : bool, optional"
msgstr ""

#: :50
msgid "Additionally compute class covariance matrix (default False)."
msgstr ""

#: :54
msgid "**tol** : float, optional"
msgstr ""

#: :56
msgid "Threshold used for rank estimation in SVD solver."
msgstr ""

#: :62
msgid "**coef_** : array, shape (n_features,) or (n_classes, n_features)"
msgstr ""

#: :64
msgid "Weight vector(s)."
msgstr ""

#: :66
msgid "**intercept_** : array, shape (n_features,)"
msgstr ""

#: :68
msgid "Intercept term."
msgstr ""

#: :70
msgid "**covariance_** : array-like, shape (n_features, n_features)"
msgstr ""

#: :72
msgid "Covariance matrix (shared by all classes)."
msgstr ""

#: :74
msgid "**explained_variance_ratio_** : array, shape (n_components,)"
msgstr ""

#: :76
msgid ""
"Percentage of variance explained by each of the selected components. If "
"``n_components`` is not set then all components are stored and the sum of"
" explained variances is equal to 1.0. Only available when eigen solver is"
" used."
msgstr ""

#: :81
msgid "**means_** : array-like, shape (n_classes, n_features)"
msgstr ""

#: :83
msgid "Class means."
msgstr ""

#: :85
msgid "**priors_** : array-like, shape (n_classes,)"
msgstr ""

#: :87
msgid "Class priors (sum to 1)."
msgstr ""

#: :89
msgid "**scalings_** : array-like, shape (rank, n_classes - 1)"
msgstr ""

#: :91
msgid "Scaling of the features in the space spanned by the class centroids."
msgstr ""

#: :93
msgid "**xbar_** : array-like, shape (n_features,)"
msgstr ""

#: :95
msgid "Overall mean."
msgstr ""

#: :97
msgid "**classes_** : array-like, shape (n_classes,)"
msgstr ""

#: :99
msgid "Unique class labels."
msgstr ""

#: :103
msgid ":obj:`sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis`"
msgstr ""

#: :104
msgid "Quadratic Discriminant Analysis"
msgstr ""

#: :107
msgid "Notes"
msgstr ""

#: :108
msgid ""
"The default solver is 'svd'. It can perform both classification and "
"transform, and it does not rely on the calculation of the covariance "
"matrix. This can be an advantage in situations where the number of "
"features is large. However, the 'svd' solver cannot be used with "
"shrinkage."
msgstr ""

#: :113
msgid ""
"The 'lsqr' solver is an efficient algorithm that only works for "
"classification. It supports shrinkage."
msgstr ""

#: :116
msgid ""
"The 'eigen' solver is based on the optimization of the between class "
"scatter to within class scatter ratio. It can be used for both "
"classification and transform, and it supports shrinkage. However, the "
"'eigen' solver needs to compute the covariance matrix, so it might not be"
" suitable for situations with a high number of features."
msgstr ""

#: :123
msgid "Examples"
msgstr ""

#: :136
msgid "Methods"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`decision_function "
"<sklearn.discriminant_analysis.LinearDiscriminantAnalysis.decision_function>`\\"
" (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Predict confidence scores for samples."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`fit "
"<sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit>`\\ (X, y[,"
" store_covariance, tol])"
msgstr ""

#: ../../<autosummary>:1
msgid ""
"Fit LinearDiscriminantAnalysis model according to the given    training "
"data and parameters."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`fit_transform "
"<sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit_transform>`\\"
" (X[, y])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Fit to data, then transform it."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`get_params "
"<sklearn.discriminant_analysis.LinearDiscriminantAnalysis.get_params>`\\ "
"([deep])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Get parameters for this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`predict "
"<sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Predict class labels for samples in X."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`predict_log_proba "
"<sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_log_proba>`\\"
" (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Estimate log probability."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`predict_proba "
"<sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_proba>`\\"
" (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Estimate probability."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`score "
"<sklearn.discriminant_analysis.LinearDiscriminantAnalysis.score>`\\ (X, "
"y[, sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Returns the mean accuracy on the given test data and labels."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`set_params "
"<sklearn.discriminant_analysis.LinearDiscriminantAnalysis.set_params>`\\ "
"(\\*\\*params)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Set the parameters of this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`transform "
"<sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform>`\\ "
"(X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Project data to maximize class separation."
msgstr ""

#: :5
msgid ""
"The confidence score for a sample is the signed distance of that sample "
"to the hyperplane."
msgstr ""

#: :10
msgid "**X** : {array-like, sparse matrix}, shape = (n_samples, n_features)"
msgstr ""

#: :12 :9
msgid "Samples."
msgstr ""

#: :16
msgid ""
"**array, shape=(n_samples,) if n_classes == 2 else (n_samples, "
"n_classes)** :"
msgstr ""

#: :18
msgid ""
"Confidence scores per (sample, class) combination. In the binary case, "
"confidence score for self.classes_[1] where >0 means this class would be "
"predicted."
msgstr ""

#: :10
msgid "Fit LinearDiscriminantAnalysis model according to the given"
msgstr ""

#: :4
msgid "training data and parameters."
msgstr ""

#: :6
msgid "Deprecated *store_covariance* have been moved to main constructor."
msgstr ""

#: :9
msgid "Deprecated *tol* have been moved to main constructor."
msgstr ""

#: :14 :7
msgid "**X** : array-like, shape (n_samples, n_features)"
msgstr ""

#: :16
msgid "Training data."
msgstr ""

#: :18
msgid "**y** : array, shape (n_samples,)"
msgstr ""

#: :20 :16
msgid "Target values."
msgstr ""

#: :5
msgid ""
"Fits transformer to X and y with optional parameters fit_params and "
"returns a transformed version of X."
msgstr ""

#: :10
msgid "**X** : numpy array of shape [n_samples, n_features]"
msgstr ""

#: :12
msgid "Training set."
msgstr ""

#: :14
msgid "**y** : numpy array of shape [n_samples]"
msgstr ""

#: :20
msgid "**X_new** : numpy array of shape [n_samples, n_features_new]"
msgstr ""

#: :22
msgid "Transformed array."
msgstr ""

#: :7
msgid "**deep: boolean, optional** :"
msgstr ""

#: :9
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: :14
msgid "**params** : mapping of string to any"
msgstr ""

#: :16
msgid "Parameter names mapped to their values."
msgstr ""

#: :7
msgid "**X** : {array-like, sparse matrix}, shape = [n_samples, n_features]"
msgstr ""

#: :13
msgid "**C** : array, shape = [n_samples]"
msgstr ""

#: :15
msgid "Predicted class label per sample."
msgstr ""

#: :9
msgid "Input data."
msgstr ""

#: :13
msgid "**C** : array, shape (n_samples, n_classes)"
msgstr ""

#: :15
msgid "Estimated log probabilities."
msgstr ""

#: :15
msgid "Estimated probabilities."
msgstr ""

#: :5
msgid ""
"In multi-label classification, this is the subset accuracy which is a "
"harsh metric since you require for each sample that each label set be "
"correctly predicted."
msgstr ""

#: :11
msgid "**X** : array-like, shape = (n_samples, n_features)"
msgstr ""

#: :13
msgid "Test samples."
msgstr ""

#: :15
msgid "**y** : array-like, shape = (n_samples) or (n_samples, n_outputs)"
msgstr ""

#: :17
msgid "True labels for X."
msgstr ""

#: :19
msgid "**sample_weight** : array-like, shape = [n_samples], optional"
msgstr ""

#: :21
msgid "Sample weights."
msgstr ""

#: :25
msgid "**score** : float"
msgstr ""

#: :27
msgid "Mean accuracy of self.predict(X) wrt. y."
msgstr ""

#: :5
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as pipelines). The former have parameters of the form "
"``<component>__<parameter>`` so that it's possible to update each "
"component of a nested object."
msgstr ""

#: :12
msgid "**self** :"
msgstr ""

#: :13
msgid "**X_new** : array, shape (n_samples, n_components)"
msgstr ""

#: :15
msgid "Transformed data."
msgstr ""

#: ../../modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.examples:3
msgid ""
"Examples using "
"``sklearn.discriminant_analysis.LinearDiscriminantAnalysis``"
msgstr ""

#: ../../modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.examples:25
msgid ":ref:`example_classification_plot_lda.py`"
msgstr ""

#: ../../modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.examples:45
msgid ":ref:`example_classification_plot_classifier_comparison.py`"
msgstr ""

#: ../../modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.examples:65
msgid ":ref:`example_classification_plot_lda_qda.py`"
msgstr ""

#: ../../modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.examples:85
msgid ":ref:`example_decomposition_plot_pca_vs_lda.py`"
msgstr ""

#: ../../modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.examples:105
msgid ":ref:`example_manifold_plot_lle_digits.py`"
msgstr ""

