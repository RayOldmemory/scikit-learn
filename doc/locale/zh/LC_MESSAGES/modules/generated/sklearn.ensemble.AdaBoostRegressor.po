# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.ensemble.AdaBoostRegressor.rst:2
msgid ":mod:`sklearn.ensemble`.AdaBoostRegressor"
msgstr ""

#: :3
msgid "An AdaBoost regressor."
msgstr ""

#: :5
msgid ""
"An AdaBoost [1] regressor is a meta-estimator that begins by fitting a "
"regressor on the original dataset and then fits additional copies of the "
"regressor on the same dataset but where the weights of instances are "
"adjusted according to the error of the current prediction. As such, "
"subsequent regressors focus more on difficult cases."
msgstr ""

#: :11
msgid "This class implements the algorithm known as AdaBoost.R2 [2]."
msgstr ""

#: :13
msgid "Read more in the :ref:`User Guide <adaboost>`."
msgstr ""

#: :17
msgid "**base_estimator** : object, optional (default=DecisionTreeRegressor)"
msgstr ""

#: :19
msgid ""
"The base estimator from which the boosted ensemble is built. Support for "
"sample weighting is required."
msgstr ""

#: :22
msgid "**n_estimators** : integer, optional (default=50)"
msgstr ""

#: :24
msgid ""
"The maximum number of estimators at which boosting is terminated. In case"
" of perfect fit, the learning procedure is stopped early."
msgstr ""

#: :27
msgid "**learning_rate** : float, optional (default=1.)"
msgstr ""

#: :29
msgid ""
"Learning rate shrinks the contribution of each regressor by "
"``learning_rate``. There is a trade-off between ``learning_rate`` and "
"``n_estimators``."
msgstr ""

#: :33
msgid ""
"**loss** : {'linear', 'square', 'exponential'}, optional "
"(default='linear')"
msgstr ""

#: :35
msgid ""
"The loss function to use when updating the weights after each boosting "
"iteration."
msgstr ""

#: :38
msgid ""
"**random_state** : int, RandomState instance or None, optional "
"(default=None)"
msgstr ""

#: :40
msgid ""
"If int, random_state is the seed used by the random number generator; If "
"RandomState instance, random_state is the random number generator; If "
"None, the random number generator is the RandomState instance used by "
"`np.random`."
msgstr ""

#: :47
msgid "**estimators_** : list of classifiers"
msgstr ""

#: :49
msgid "The collection of fitted sub-estimators."
msgstr ""

#: :51
msgid "**estimator_weights_** : array of floats"
msgstr ""

#: :53
msgid "Weights for each estimator in the boosted ensemble."
msgstr ""

#: :55
msgid "**estimator_errors_** : array of floats"
msgstr ""

#: :57
msgid "Regression error for each estimator in the boosted ensemble."
msgstr ""

#: :59
msgid "**feature_importances_** : array of shape = [n_features]"
msgstr ""

#: :61
msgid "The feature importances if supported by the ``base_estimator``."
msgstr ""

#: :65
msgid ""
":obj:`AdaBoostClassifier`, :obj:`GradientBoostingRegressor`, "
":obj:`DecisionTreeRegressor`"
msgstr ""

#: :68
msgid "References"
msgstr ""

#: :69
msgid ""
"Y. Freund, R. Schapire, \"A Decision-Theoretic Generalization of on-Line "
"Learning and an Application to Boosting\", 1995."
msgstr ""

#: :72
msgid "Drucker, \"Improving Regressors using Boosting Techniques\", 1997."
msgstr ""

#: :79
msgid "Methods"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`fit <sklearn.ensemble.AdaBoostRegressor.fit>`\\ (X, y[, "
"sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Build a boosted regressor from the training set (X, y)."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`get_params <sklearn.ensemble.AdaBoostRegressor.get_params>`\\ "
"([deep])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Get parameters for this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`predict <sklearn.ensemble.AdaBoostRegressor.predict>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Predict regression value for X."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`score <sklearn.ensemble.AdaBoostRegressor.score>`\\ (X, y[, "
"sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Returns the coefficient of determination R^2 of the prediction."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`set_params <sklearn.ensemble.AdaBoostRegressor.set_params>`\\ "
"(\\*\\*params)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Set the parameters of this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`staged_predict "
"<sklearn.ensemble.AdaBoostRegressor.staged_predict>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Return staged predictions for X."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`staged_score <sklearn.ensemble.AdaBoostRegressor.staged_score>`\\ "
"(X, y[, sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Return staged scores for X, y."
msgstr ""

#: :4
msgid "Return the feature importances (the higher, the more important the"
msgstr ""

#: :4
msgid "feature)."
msgstr ""

#: :8
msgid "**feature_importances_** : array, shape = [n_features]"
msgstr ""

#: :7 :10 :14 :11
msgid "**X** : {array-like, sparse matrix} of shape = [n_samples, n_features]"
msgstr ""

#: :9 :12 :16 :13
msgid ""
"The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or "
"LIL. DOK and LIL are converted to CSR."
msgstr ""

#: :12
msgid "**y** : array-like of shape = [n_samples]"
msgstr ""

#: :14
msgid "The target values (real numbers)."
msgstr ""

#: :16
msgid "**sample_weight** : array-like of shape = [n_samples], optional"
msgstr ""

#: :18
msgid ""
"Sample weights. If None, the sample weights are initialized to 1 / "
"n_samples."
msgstr ""

#: :23
msgid "**self** : object"
msgstr ""

#: :25
msgid "Returns self."
msgstr ""

#: :7
msgid "**deep: boolean, optional** :"
msgstr ""

#: :9
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: :14
msgid "**params** : mapping of string to any"
msgstr ""

#: :16
msgid "Parameter names mapped to their values."
msgstr ""

#: :5
msgid ""
"The predicted regression value of an input sample is computed as the "
"weighted median prediction of the classifiers in the ensemble."
msgstr ""

#: :17
msgid "**y** : array of shape = [n_samples]"
msgstr ""

#: :19 :23
msgid "The predicted regression values."
msgstr ""

#: :5
msgid ""
"The coefficient R^2 is defined as (1 - u/v), where u is the regression "
"sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual sum "
"of squares ((y_true - y_true.mean()) ** 2).sum(). Best possible score is "
"1.0 and it can be negative (because the model can be arbitrarily worse). "
"A constant model that always predicts the expected value of y, "
"disregarding the input features, would get a R^2 score of 0.0."
msgstr ""

#: :15
msgid "**X** : array-like, shape = (n_samples, n_features)"
msgstr ""

#: :17
msgid "Test samples."
msgstr ""

#: :19
msgid "**y** : array-like, shape = (n_samples) or (n_samples, n_outputs)"
msgstr ""

#: :21
msgid "True values for X."
msgstr ""

#: :23 :20
msgid "**sample_weight** : array-like, shape = [n_samples], optional"
msgstr ""

#: :25 :22
msgid "Sample weights."
msgstr ""

#: :29
msgid "**score** : float"
msgstr ""

#: :31
msgid "R^2 of self.predict(X) wrt. y."
msgstr ""

#: :5
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as pipelines). The former have parameters of the form "
"``<component>__<parameter>`` so that it's possible to update each "
"component of a nested object."
msgstr ""

#: :12
msgid "**self** :"
msgstr ""

#: :8
msgid ""
"This generator method yields the ensemble prediction after each iteration"
" of boosting and therefore allows monitoring, such as to determine the "
"prediction on a test set after each boost."
msgstr ""

#: :21
msgid "**y** : generator of array, shape = [n_samples]"
msgstr ""

#: :5
msgid ""
"This generator method yields the ensemble score after each iteration of "
"boosting and therefore allows monitoring, such as to determine the score "
"on a test set after each boost."
msgstr ""

#: :16
msgid "**y** : array-like, shape = [n_samples]"
msgstr ""

#: :18
msgid "Labels for X."
msgstr ""

#: :26
msgid "**z** : float"
msgstr ""

#: ../../modules/generated/sklearn.ensemble.AdaBoostRegressor.examples:3
msgid "Examples using ``sklearn.ensemble.AdaBoostRegressor``"
msgstr ""

#: ../../modules/generated/sklearn.ensemble.AdaBoostRegressor.examples:25
msgid ":ref:`example_ensemble_plot_adaboost_regression.py`"
msgstr ""

