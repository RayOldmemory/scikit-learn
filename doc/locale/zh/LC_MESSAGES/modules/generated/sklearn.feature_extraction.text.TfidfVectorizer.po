# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.rst:2
msgid ":mod:`sklearn.feature_extraction.text`.TfidfVectorizer"
msgstr ""

#: :3
msgid "Convert a collection of raw documents to a matrix of TF-IDF features."
msgstr ""

#: :5
msgid "Equivalent to CountVectorizer followed by TfidfTransformer."
msgstr ""

#: :7
msgid "Read more in the :ref:`User Guide <text_feature_extraction>`."
msgstr ""

#: :11
msgid "**input** : string {'filename', 'file', 'content'}"
msgstr ""

#: :13
msgid ""
"If 'filename', the sequence passed as an argument to fit is expected to "
"be a list of filenames that need reading to fetch the raw content to "
"analyze."
msgstr ""

#: :17
msgid ""
"If 'file', the sequence items must have a 'read' method (file-like "
"object) that is called to fetch the bytes in memory."
msgstr ""

#: :20
msgid ""
"Otherwise the input is expected to be the sequence strings or bytes items"
" are expected to be analyzed directly."
msgstr ""

#: :23
msgid "**encoding** : string, 'utf-8' by default."
msgstr ""

#: :25
msgid "If bytes or files are given to analyze, this encoding is used to decode."
msgstr ""

#: :28
msgid "**decode_error** : {'strict', 'ignore', 'replace'}"
msgstr ""

#: :30
msgid ""
"Instruction on what to do if a byte sequence is given to analyze that "
"contains characters not of the given `encoding`. By default, it is "
"'strict', meaning that a UnicodeDecodeError will be raised. Other values "
"are 'ignore' and 'replace'."
msgstr ""

#: :35
msgid "**strip_accents** : {'ascii', 'unicode', None}"
msgstr ""

#: :37
msgid ""
"Remove accents during the preprocessing step. 'ascii' is a fast method "
"that only works on characters that have an direct ASCII mapping. "
"'unicode' is a slightly slower method that works on any characters. None "
"(default) does nothing."
msgstr ""

#: :43
msgid "**analyzer** : string, {'word', 'char'} or callable"
msgstr ""

#: :45
msgid "Whether the feature should be made of word or character n-grams."
msgstr ""

#: :47
msgid ""
"If a callable is passed it is used to extract the sequence of features "
"out of the raw, unprocessed input."
msgstr ""

#: :50
msgid "**preprocessor** : callable or None (default)"
msgstr ""

#: :52
msgid ""
"Override the preprocessing (string transformation) stage while preserving"
" the tokenizing and n-grams generation steps."
msgstr ""

#: :55
msgid "**tokenizer** : callable or None (default)"
msgstr ""

#: :57
msgid ""
"Override the string tokenization step while preserving the preprocessing "
"and n-grams generation steps. Only applies if ``analyzer == 'word'``."
msgstr ""

#: :61
msgid "**ngram_range** : tuple (min_n, max_n)"
msgstr ""

#: :63
msgid ""
"The lower and upper boundary of the range of n-values for different "
"n-grams to be extracted. All values of n such that min_n <= n <= max_n "
"will be used."
msgstr ""

#: :67
msgid "**stop_words** : string {'english'}, list, or None (default)"
msgstr ""

#: :69
msgid ""
"If a string, it is passed to _check_stop_list and the appropriate stop "
"list is returned. 'english' is currently the only supported string value."
msgstr ""

#: :73
msgid ""
"If a list, that list is assumed to contain stop words, all of which will "
"be removed from the resulting tokens. Only applies if ``analyzer == "
"'word'``."
msgstr ""

#: :77
msgid ""
"If None, no stop words will be used. max_df can be set to a value in the "
"range [0.7, 1.0) to automatically detect and filter stop words based on "
"intra corpus document frequency of terms."
msgstr ""

#: :81
msgid "**lowercase** : boolean, default True"
msgstr ""

#: :83
msgid "Convert all characters to lowercase before tokenizing."
msgstr ""

#: :85
msgid "**token_pattern** : string"
msgstr ""

#: :87
msgid ""
"Regular expression denoting what constitutes a \"token\", only used if "
"``analyzer == 'word'``. The default regexp selects tokens of 2 or more "
"alphanumeric characters (punctuation is completely ignored and always "
"treated as a token separator)."
msgstr ""

#: :92
msgid "**max_df** : float in range [0.0, 1.0] or int, default=1.0"
msgstr ""

#: :94
msgid ""
"When building the vocabulary ignore terms that have a document frequency "
"strictly higher than the given threshold (corpus-specific stop words). If"
" float, the parameter represents a proportion of documents, integer "
"absolute counts. This parameter is ignored if vocabulary is not None."
msgstr ""

#: :101
msgid "**min_df** : float in range [0.0, 1.0] or int, default=1"
msgstr ""

#: :103
msgid ""
"When building the vocabulary ignore terms that have a document frequency "
"strictly lower than the given threshold. This value is also called cut-"
"off in the literature. If float, the parameter represents a proportion of"
" documents, integer absolute counts. This parameter is ignored if "
"vocabulary is not None."
msgstr ""

#: :110
msgid "**max_features** : int or None, default=None"
msgstr ""

#: :112
msgid ""
"If not None, build a vocabulary that only consider the top max_features "
"ordered by term frequency across the corpus."
msgstr ""

#: :115
msgid "This parameter is ignored if vocabulary is not None."
msgstr ""

#: :117
msgid "**vocabulary** : Mapping or iterable, optional"
msgstr ""

#: :119
msgid ""
"Either a Mapping (e.g., a dict) where keys are terms and values are "
"indices in the feature matrix, or an iterable over terms. If not given, a"
" vocabulary is determined from the input documents."
msgstr ""

#: :123
msgid "**binary** : boolean, default=False"
msgstr ""

#: :125
msgid ""
"If True, all non-zero term counts are set to 1. This does not mean "
"outputs will have only 0/1 values, only that the tf term in tf-idf is "
"binary. (Set idf and normalization to False to get 0/1 outputs.)"
msgstr ""

#: :129
msgid "**dtype** : type, optional"
msgstr ""

#: :131
msgid "Type of the matrix returned by fit_transform() or transform()."
msgstr ""

#: :133
msgid "**norm** : 'l1', 'l2' or None, optional"
msgstr ""

#: :135
msgid "Norm used to normalize term vectors. None for no normalization."
msgstr ""

#: :137
msgid "**use_idf** : boolean, default=True"
msgstr ""

#: :139
msgid "Enable inverse-document-frequency reweighting."
msgstr ""

#: :141
msgid "**smooth_idf** : boolean, default=True"
msgstr ""

#: :143
msgid ""
"Smooth idf weights by adding one to document frequencies, as if an extra "
"document was seen containing every term in the collection exactly once. "
"Prevents zero divisions."
msgstr ""

#: :147
msgid "**sublinear_tf** : boolean, default=False"
msgstr ""

#: :149
msgid "Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf)."
msgstr ""

#: :153
msgid "**idf_** : array, shape = [n_features], or None"
msgstr ""

#: :155
msgid ""
"The learned idf vector (global term weights) when ``use_idf`` is set to "
"True, None otherwise."
msgstr ""

#: :158
msgid "**stop_words_** : set"
msgstr ""

#: :160
msgid "Terms that were ignored because they either:"
msgstr ""

#: :162
msgid "occurred in too many documents (`max_df`)"
msgstr ""

#: :163
msgid "occurred in too few documents (`min_df`)"
msgstr ""

#: :164
msgid "were cut off by feature selection (`max_features`)."
msgstr ""

#: :166
msgid "This is only available if no vocabulary was given."
msgstr ""

#: :171
msgid ":obj:`CountVectorizer`"
msgstr ""

#: :171
msgid ""
"Tokenize the documents and count the occurrences of token and return them"
" as a sparse matrix"
msgstr ""

#: :173
msgid ":obj:`TfidfTransformer`"
msgstr ""

#: :174
msgid ""
"Apply Term Frequency Inverse Document Frequency normalization to a sparse"
" matrix of occurrence counts."
msgstr ""

#: :177
msgid "Notes"
msgstr ""

#: :178
msgid ""
"The ``stop_words_`` attribute can get large and increase the model size "
"when pickling. This attribute is provided only for introspection and can "
"be safely removed using delattr or set to None before pickling."
msgstr ""

#: :183
msgid "Methods"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`build_analyzer "
"<sklearn.feature_extraction.text.TfidfVectorizer.build_analyzer>`\\ ()"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Return a callable that handles preprocessing and tokenization"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`build_preprocessor "
"<sklearn.feature_extraction.text.TfidfVectorizer.build_preprocessor>`\\ "
"()"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Return a function to preprocess the text before tokenization"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`build_tokenizer "
"<sklearn.feature_extraction.text.TfidfVectorizer.build_tokenizer>`\\ ()"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Return a function that splits a string into a sequence of tokens"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`decode <sklearn.feature_extraction.text.TfidfVectorizer.decode>`\\ "
"(doc)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Decode the input into a string of unicode symbols"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`fit <sklearn.feature_extraction.text.TfidfVectorizer.fit>`\\ "
"(raw_documents[, y])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Learn vocabulary and idf from training set."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`fit_transform "
"<sklearn.feature_extraction.text.TfidfVectorizer.fit_transform>`\\ "
"(raw_documents[, y])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Learn vocabulary and idf, return term-document matrix."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`get_feature_names "
"<sklearn.feature_extraction.text.TfidfVectorizer.get_feature_names>`\\ ()"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Array mapping from feature integer indices to feature name"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`get_params "
"<sklearn.feature_extraction.text.TfidfVectorizer.get_params>`\\ ([deep])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Get parameters for this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`get_stop_words "
"<sklearn.feature_extraction.text.TfidfVectorizer.get_stop_words>`\\ ()"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Build or fetch the effective stop words list"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`inverse_transform "
"<sklearn.feature_extraction.text.TfidfVectorizer.inverse_transform>`\\ "
"(X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Return terms per document with nonzero entries in X."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`set_params "
"<sklearn.feature_extraction.text.TfidfVectorizer.set_params>`\\ "
"(\\*\\*params)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Set the parameters of this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`transform "
"<sklearn.feature_extraction.text.TfidfVectorizer.transform>`\\ "
"(raw_documents[, copy])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Transform documents to document-term matrix."
msgstr ""

#: :5
msgid "The decoding strategy depends on the vectorizer parameters."
msgstr ""

#: :7 :10
msgid "**raw_documents** : iterable"
msgstr ""

#: :9 :12
msgid "an iterable which yields either str, unicode or file objects"
msgstr ""

#: :13
msgid "**self** : TfidfVectorizer"
msgstr ""

#: :5
msgid ""
"This is equivalent to fit followed by transform, but more efficiently "
"implemented."
msgstr ""

#: :16 :21
msgid "**X** : sparse matrix, [n_samples, n_features]"
msgstr ""

#: :18 :23
msgid "Tf-idf-weighted document-term matrix."
msgstr ""

#: :3
msgid ""
"DEPRECATED: The `fixed_vocabulary` attribute is deprecated and will be "
"removed in 0.18.  Please use `fixed_vocabulary_` instead."
msgstr ""

#: :7
msgid "**deep: boolean, optional** :"
msgstr ""

#: :9
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: :14
msgid "**params** : mapping of string to any"
msgstr ""

#: :16
msgid "Parameter names mapped to their values."
msgstr ""

#: :7
msgid "**X** : {array, sparse matrix}, shape = [n_samples, n_features]"
msgstr ""

#: :11
msgid "**X_inv** : list of arrays, len = n_samples"
msgstr ""

#: :13
msgid "List of arrays of terms."
msgstr ""

#: :5
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as pipelines). The former have parameters of the form "
"``<component>__<parameter>`` so that it's possible to update each "
"component of a nested object."
msgstr ""

#: :12
msgid "**self** :"
msgstr ""

#: :5
msgid ""
"Uses the vocabulary and document frequencies (df) learned by fit (or "
"fit_transform)."
msgstr ""

#: :14
msgid "**copy** : boolean, default True"
msgstr ""

#: :16
msgid "Whether to copy X and operate on the copy or perform in-place operations."
msgstr ""

#: ../../modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.examples:3
msgid "Examples using ``sklearn.feature_extraction.text.TfidfVectorizer``"
msgstr ""

#: ../../modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.examples:25
msgid ":ref:`example_hetero_feature_union.py`"
msgstr ""

#: ../../modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.examples:45
msgid ":ref:`example_applications_topics_extraction_with_nmf_lda.py`"
msgstr ""

#: ../../modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.examples:65
msgid ":ref:`example_bicluster_bicluster_newsgroups.py`"
msgstr ""

#: ../../modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.examples:85
msgid ":ref:`example_text_mlcomp_sparse_document_classification.py`"
msgstr ""

#: ../../modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.examples:105
msgid ":ref:`example_text_document_clustering.py`"
msgstr ""

#: ../../modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.examples:125
msgid ":ref:`example_text_document_classification_20newsgroups.py`"
msgstr ""

