# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.grid_search.RandomizedSearchCV.rst:2
msgid ":mod:`sklearn.grid_search`.RandomizedSearchCV"
msgstr ""

#: :3
msgid "Randomized search on hyper parameters."
msgstr ""

#: :5
msgid ""
"RandomizedSearchCV implements a \"fit\" and a \"score\" method. It also "
"implements \"predict\", \"predict_proba\", \"decision_function\", "
"\"transform\" and \"inverse_transform\" if they are implemented in the "
"estimator used."
msgstr ""

#: :10
msgid ""
"The parameters of the estimator used to apply these methods are optimized"
" by cross-validated search over parameter settings."
msgstr ""

#: :13
msgid ""
"In contrast to GridSearchCV, not all parameter values are tried out, but "
"rather a fixed number of parameter settings is sampled from the specified"
" distributions. The number of parameter settings that are tried is given "
"by n_iter."
msgstr ""

#: :18
msgid ""
"If all parameters are presented as a list, sampling without replacement "
"is performed. If at least one parameter is given as a distribution, "
"sampling with replacement is used. It is highly recommended to use "
"continuous distributions for continuous parameters."
msgstr ""

#: :24
msgid "Read more in the :ref:`User Guide <randomized_parameter_search>`."
msgstr ""

#: :28
msgid "**estimator** : estimator object."
msgstr ""

#: :30
msgid ""
"A object of that type is instantiated for each grid point. This is "
"assumed to implement the scikit-learn estimator interface. Either "
"estimator needs to provide a ``score`` function, or ``scoring`` must be "
"passed."
msgstr ""

#: :35
msgid "**param_distributions** : dict"
msgstr ""

#: :37
msgid ""
"Dictionary with parameters names (string) as keys and distributions or "
"lists of parameters to try. Distributions must provide a ``rvs`` method "
"for sampling (such as those from scipy.stats.distributions). If a list is"
" given, it is sampled uniformly."
msgstr ""

#: :42
msgid "**n_iter** : int, default=10"
msgstr ""

#: :44
msgid ""
"Number of parameter settings that are sampled. n_iter trades off runtime "
"vs quality of the solution."
msgstr ""

#: :47
msgid "**scoring** : string, callable or None, default=None"
msgstr ""

#: :49
msgid ""
"A string (see model evaluation documentation) or a scorer callable object"
" / function with signature ``scorer(estimator, X, y)``. If ``None``, the "
"``score`` method of the estimator is used."
msgstr ""

#: :54
msgid "**fit_params** : dict, optional"
msgstr ""

#: :56
msgid "Parameters to pass to the fit method."
msgstr ""

#: :58
msgid "**n_jobs** : int, default=1"
msgstr ""

#: :60
msgid "Number of jobs to run in parallel."
msgstr ""

#: :62
msgid "**pre_dispatch** : int, or string, optional"
msgstr ""

#: :64
msgid ""
"Controls the number of jobs that get dispatched during parallel "
"execution. Reducing this number can be useful to avoid an explosion of "
"memory consumption when more jobs get dispatched than CPUs can process. "
"This parameter can be:"
msgstr ""

#: :69
msgid ""
"None, in which case all the jobs are immediately created and spawned. Use"
" this for lightweight and fast-running jobs, to avoid delays due to on-"
"demand spawning of the jobs"
msgstr ""

#: :74
msgid "An int, giving the exact number of total jobs that are spawned"
msgstr ""

#: :77
msgid "A string, giving an expression as a function of n_jobs, as in '2*n_jobs'"
msgstr ""

#: :80
msgid "**iid** : boolean, default=True"
msgstr ""

#: :82
msgid ""
"If True, the data is assumed to be identically distributed across the "
"folds, and the loss minimized is the total loss per sample, and not the "
"mean loss across the folds."
msgstr ""

#: :86
msgid "**cv** : int, cross-validation generator or an iterable, optional"
msgstr ""

#: :88
msgid ""
"Determines the cross-validation splitting strategy. Possible inputs for "
"cv are:"
msgstr ""

#: :91
msgid "None, to use the default 3-fold cross-validation,"
msgstr ""

#: :92
msgid "integer, to specify the number of folds."
msgstr ""

#: :93
msgid "An object to be used as a cross-validation generator."
msgstr ""

#: :94
msgid "An iterable yielding train/test splits."
msgstr ""

#: :96
msgid ""
"For integer/None inputs, if ``y`` is binary or multiclass, "
":class:`StratifiedKFold` used. If the estimator is a classifier or if "
"``y`` is neither binary nor multiclass, :class:`KFold` is used."
msgstr ""

#: :100
msgid ""
"Refer :ref:`User Guide <cross_validation>` for the various cross-"
"validation strategies that can be used here."
msgstr ""

#: :103
msgid "**refit** : boolean, default=True"
msgstr ""

#: :105
msgid ""
"Refit the best estimator with the entire dataset. If \"False\", it is "
"impossible to make predictions using this RandomizedSearchCV instance "
"after fitting."
msgstr ""

#: :109
msgid "**verbose** : integer"
msgstr ""

#: :111
msgid "Controls the verbosity: the higher, the more messages."
msgstr ""

#: :113
msgid "**random_state** : int or RandomState"
msgstr ""

#: :115
msgid ""
"Pseudo random number generator state used for random uniform sampling "
"from lists of possible values instead of scipy.stats distributions."
msgstr ""

#: :118
msgid "**error_score** : 'raise' (default) or numeric"
msgstr ""

#: :120
msgid ""
"Value to assign to the score if an error occurs in estimator fitting. If "
"set to 'raise', the error is raised. If a numeric value is given, "
"FitFailedWarning is raised. This parameter does not affect the refit "
"step, which will always raise the error."
msgstr ""

#: :127
msgid "**grid_scores_** : list of named tuples"
msgstr ""

#: :129
msgid ""
"Contains scores for all parameter combinations in param_grid. Each entry "
"corresponds to one parameter setting. Each named tuple has the "
"attributes:"
msgstr ""

#: :133
msgid "``parameters``, a dict of parameter settings"
msgstr ""

#: :134
msgid "``mean_validation_score``, the mean score over the cross-validation folds"
msgstr ""

#: :136
msgid "``cv_validation_scores``, the list of scores for each fold"
msgstr ""

#: :138
msgid "**best_estimator_** : estimator"
msgstr ""

#: :140
msgid ""
"Estimator that was chosen by the search, i.e. estimator which gave "
"highest score (or smallest loss if specified) on the left out data. Not "
"available if refit=False."
msgstr ""

#: :144
msgid "**best_score_** : float"
msgstr ""

#: :146
msgid "Score of best_estimator on the left out data."
msgstr ""

#: :148
msgid "**best_params_** : dict"
msgstr ""

#: :150
msgid "Parameter setting that gave the best results on the hold out data."
msgstr ""

#: :155
msgid ":class:`GridSearchCV`"
msgstr ""

#: :155
msgid "Does exhaustive search over a grid of parameters."
msgstr ""

#: :157
msgid ":class:`ParameterSampler`"
msgstr ""

#: :158
msgid "A generator over parameter settins, constructed from param_distributions."
msgstr ""

#: :161 :25
msgid "Notes"
msgstr ""

#: :162
msgid ""
"The parameters selected are those that maximize the score of the held-out"
" data, according to the scoring parameter."
msgstr ""

#: :165
msgid ""
"If `n_jobs` was set to a value higher than one, the data is copied for "
"each parameter setting(and not `n_jobs` times). This is done for "
"efficiency reasons if individual jobs take very little time, but may "
"raise errors if the dataset is large and not enough memory is available."
"  A workaround in this case is to set `pre_dispatch`. Then, the memory is"
" copied only `pre_dispatch` many times. A reasonable value for "
"`pre_dispatch` is `2 * n_jobs`."
msgstr ""

#: :174
msgid "Methods"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`decision_function "
"<sklearn.grid_search.RandomizedSearchCV.decision_function>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Call decision_function on the estimator with the best found parameters."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`fit <sklearn.grid_search.RandomizedSearchCV.fit>`\\ (X[, y])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Run fit on the estimator with randomly drawn parameters."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`get_params <sklearn.grid_search.RandomizedSearchCV.get_params>`\\ "
"([deep])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Get parameters for this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`inverse_transform "
"<sklearn.grid_search.RandomizedSearchCV.inverse_transform>`\\ (Xt)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Call inverse_transform on the estimator with the best found parameters."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`predict <sklearn.grid_search.RandomizedSearchCV.predict>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Call predict on the estimator with the best found parameters."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`predict_log_proba "
"<sklearn.grid_search.RandomizedSearchCV.predict_log_proba>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Call predict_log_proba on the estimator with the best found parameters."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`predict_proba "
"<sklearn.grid_search.RandomizedSearchCV.predict_proba>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Call predict_proba on the estimator with the best found parameters."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`score <sklearn.grid_search.RandomizedSearchCV.score>`\\ (X[, y])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Returns the score on the given data, if the estimator has been refit."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`set_params <sklearn.grid_search.RandomizedSearchCV.set_params>`\\ "
"(\\*\\*params)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Set the parameters of this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`transform <sklearn.grid_search.RandomizedSearchCV.transform>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Call transform on the estimator with the best found parameters."
msgstr ""

#: :5
msgid ""
"Only available if ``refit=True`` and the underlying estimator supports "
"``decision_function``."
msgstr ""

#: :10
msgid "**X** : indexable, length n_samples"
msgstr ""

#: :12
msgid "Must fulfill the input assumptions of the underlying estimator."
msgstr ""

#: :7 :10
msgid "**X** : array-like, shape = [n_samples, n_features]"
msgstr ""

#: :9
msgid ""
"Training vector, where n_samples in the number of samples and n_features "
"is the number of features."
msgstr ""

#: :12 :15
msgid "**y** : array-like, shape = [n_samples] or [n_samples, n_output], optional"
msgstr ""

#: :14 :17
msgid ""
"Target relative to X for classification or regression; None for "
"unsupervised learning."
msgstr ""

#: :7
msgid "**deep: boolean, optional** :"
msgstr ""

#: :9
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: :14
msgid "**params** : mapping of string to any"
msgstr ""

#: :16
msgid "Parameter names mapped to their values."
msgstr ""

#: :5
msgid ""
"Only available if the underlying estimator implements "
"``inverse_transform`` and ``refit=True``."
msgstr ""

#: :10
msgid "**Xt** : indexable, length n_samples"
msgstr ""

#: :5
msgid ""
"Only available if ``refit=True`` and the underlying estimator supports "
"``predict``."
msgstr ""

#: :5
msgid ""
"Only available if ``refit=True`` and the underlying estimator supports "
"``predict_log_proba``."
msgstr ""

#: :5
msgid ""
"Only available if ``refit=True`` and the underlying estimator supports "
"``predict_proba``."
msgstr ""

#: :5
msgid ""
"This uses the score defined by ``scoring`` where provided, and the "
"``best_estimator_.score`` method otherwise."
msgstr ""

#: :12
msgid ""
"Input data, where n_samples is the number of samples and n_features is "
"the number of features."
msgstr ""

#: :22
msgid "**score** : float"
msgstr ""

#: :26
msgid "The long-standing behavior of this method changed in version 0.16."
msgstr ""

#: :27
msgid ""
"It no longer uses the metric provided by ``estimator.score`` if the "
"``scoring`` parameter was set when fitting."
msgstr ""

#: :5
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as pipelines). The former have parameters of the form "
"``<component>__<parameter>`` so that it's possible to update each "
"component of a nested object."
msgstr ""

#: :12
msgid "**self** :"
msgstr ""

#: :5
msgid ""
"Only available if the underlying estimator supports ``transform`` and "
"``refit=True``."
msgstr ""

#: ../../modules/generated/sklearn.grid_search.RandomizedSearchCV.examples:3
msgid "Examples using ``sklearn.grid_search.RandomizedSearchCV``"
msgstr ""

#: ../../modules/generated/sklearn.grid_search.RandomizedSearchCV.examples:25
msgid ":ref:`example_model_selection_randomized_search.py`"
msgstr ""

