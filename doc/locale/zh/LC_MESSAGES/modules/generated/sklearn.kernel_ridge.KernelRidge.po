# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.kernel_ridge.KernelRidge.rst:2
msgid ":mod:`sklearn.kernel_ridge`.KernelRidge"
msgstr ""

#: :3
msgid "Kernel ridge regression."
msgstr ""

#: :5
msgid ""
"Kernel ridge regression (KRR) combines ridge regression (linear least "
"squares with l2-norm regularization) with the kernel trick. It thus "
"learns a linear function in the space induced by the respective kernel "
"and the data. For non-linear kernels, this corresponds to a non-linear "
"function in the original space."
msgstr ""

#: :11
msgid ""
"The form of the model learned by KRR is identical to support vector "
"regression (SVR). However, different loss functions are used: KRR uses "
"squared error loss while support vector regression uses epsilon-"
"insensitive loss, both combined with l2 regularization. In contrast to "
"SVR, fitting a KRR model can be done in closed-form and is typically "
"faster for medium-sized datasets. On the other  hand, the learned model "
"is non-sparse and thus slower than SVR, which learns a sparse model for "
"epsilon > 0, at prediction-time."
msgstr ""

#: :20
msgid ""
"This estimator has built-in support for multi-variate regression (i.e., "
"when y is a 2d-array of shape [n_samples, n_targets])."
msgstr ""

#: :23
msgid "Read more in the :ref:`User Guide <kernel_ridge>`."
msgstr ""

#: :27
msgid "**alpha** : {float, array-like}, shape = [n_targets]"
msgstr ""

#: :29
msgid ""
"Small positive values of alpha improve the conditioning of the problem "
"and reduce the variance of the estimates.  Alpha corresponds to "
"``(2*C)^-1`` in other linear models such as LogisticRegression or "
"LinearSVC. If an array is passed, penalties are assumed to be specific to"
" the targets. Hence they must correspond in number."
msgstr ""

#: :35
msgid "**kernel** : string or callable, default=\"linear\""
msgstr ""

#: :37
msgid ""
"Kernel mapping used internally. A callable should accept two arguments "
"and the keyword arguments passed to this object as kernel_params, and "
"should return a floating point number."
msgstr ""

#: :41
msgid "**gamma** : float, default=None"
msgstr ""

#: :43
msgid ""
"Gamma parameter for the RBF, laplacian, polynomial, exponential chi2 and "
"sigmoid kernels. Interpretation of the default value is left to the "
"kernel; see the documentation for sklearn.metrics.pairwise. Ignored by "
"other kernels."
msgstr ""

#: :48
msgid "**degree** : float, default=3"
msgstr ""

#: :50
msgid "Degree of the polynomial kernel. Ignored by other kernels."
msgstr ""

#: :52
msgid "**coef0** : float, default=1"
msgstr ""

#: :54
msgid ""
"Zero coefficient for polynomial and sigmoid kernels. Ignored by other "
"kernels."
msgstr ""

#: :57
msgid "**kernel_params** : mapping of string to any, optional"
msgstr ""

#: :59
msgid ""
"Additional parameters (keyword arguments) for kernel function passed as "
"callable object."
msgstr ""

#: :64
msgid "**dual_coef_** : array, shape = [n_features] or [n_targets, n_features]"
msgstr ""

#: :66
msgid "Weight vector(s) in kernel space"
msgstr ""

#: :68
msgid "**X_fit_** : {array-like, sparse matrix}, shape = [n_samples, n_features]"
msgstr ""

#: :70
msgid "Training data, which is also required for prediction"
msgstr ""

#: :75
msgid ":obj:`Ridge`"
msgstr ""

#: :75
msgid "Linear ridge regression."
msgstr ""

#: :77
msgid ":obj:`SVR`"
msgstr ""

#: :78
msgid "Support Vector Regression implemented using libsvm."
msgstr ""

#: :81
msgid "References"
msgstr ""

#: :82
msgid ""
"Kevin P. Murphy \"Machine Learning: A Probabilistic Perspective\", The "
"MIT Press chapter 14.4.3, pp. 492-493"
msgstr ""

#: :89
msgid "Examples"
msgstr ""

#: :102
msgid "Methods"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`fit <sklearn.kernel_ridge.KernelRidge.fit>`\\ (X[, y, "
"sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Fit Kernel Ridge regression model"
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`get_params <sklearn.kernel_ridge.KernelRidge.get_params>`\\ ([deep])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Get parameters for this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`predict <sklearn.kernel_ridge.KernelRidge.predict>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Predict using the the kernel ridge model"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`score <sklearn.kernel_ridge.KernelRidge.score>`\\ (X, y[, "
"sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Returns the coefficient of determination R^2 of the prediction."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`set_params <sklearn.kernel_ridge.KernelRidge.set_params>`\\ "
"(\\*\\*params)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Set the parameters of this estimator."
msgstr ""

#: :7
msgid "**X** : {array-like, sparse matrix}, shape = [n_samples, n_features]"
msgstr ""

#: :9
msgid "Training data"
msgstr ""

#: :11
msgid "**y** : array-like, shape = [n_samples] or [n_samples, n_targets]"
msgstr ""

#: :13
msgid "Target values"
msgstr ""

#: :15
msgid "**sample_weight** : float or numpy array of shape [n_samples]"
msgstr ""

#: :17
msgid "Individual weights for each sample, ignored if None is passed."
msgstr ""

#: :21
msgid "**self** : returns an instance of self."
msgstr ""

#: :7
msgid "**deep: boolean, optional** :"
msgstr ""

#: :9
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: :14
msgid "**params** : mapping of string to any"
msgstr ""

#: :16
msgid "Parameter names mapped to their values."
msgstr ""

#: :9
msgid "Samples."
msgstr ""

#: :13
msgid "**C** : array, shape = [n_samples] or [n_samples, n_targets]"
msgstr ""

#: :15
msgid "Returns predicted values."
msgstr ""

#: :5
msgid ""
"The coefficient R^2 is defined as (1 - u/v), where u is the regression "
"sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual sum "
"of squares ((y_true - y_true.mean()) ** 2).sum(). Best possible score is "
"1.0 and it can be negative (because the model can be arbitrarily worse). "
"A constant model that always predicts the expected value of y, "
"disregarding the input features, would get a R^2 score of 0.0."
msgstr ""

#: :15
msgid "**X** : array-like, shape = (n_samples, n_features)"
msgstr ""

#: :17
msgid "Test samples."
msgstr ""

#: :19
msgid "**y** : array-like, shape = (n_samples) or (n_samples, n_outputs)"
msgstr ""

#: :21
msgid "True values for X."
msgstr ""

#: :23
msgid "**sample_weight** : array-like, shape = [n_samples], optional"
msgstr ""

#: :25
msgid "Sample weights."
msgstr ""

#: :29
msgid "**score** : float"
msgstr ""

#: :31
msgid "R^2 of self.predict(X) wrt. y."
msgstr ""

#: :5
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as pipelines). The former have parameters of the form "
"``<component>__<parameter>`` so that it's possible to update each "
"component of a nested object."
msgstr ""

#: :12
msgid "**self** :"
msgstr ""

#: ../../modules/generated/sklearn.kernel_ridge.KernelRidge.examples:3
msgid "Examples using ``sklearn.kernel_ridge.KernelRidge``"
msgstr ""

#: ../../modules/generated/sklearn.kernel_ridge.KernelRidge.examples:25
msgid ":ref:`example_plot_kernel_ridge_regression.py`"
msgstr ""

