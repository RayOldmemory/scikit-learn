# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.linear_model.Ridge.rst:2
msgid ":mod:`sklearn.linear_model`.Ridge"
msgstr ""

#: :3
msgid "Linear least squares with l2 regularization."
msgstr ""

#: :5
msgid ""
"This model solves a regression model where the loss function is the "
"linear least squares function and regularization is given by the l2-norm."
" Also known as Ridge Regression or Tikhonov regularization. This "
"estimator has built-in support for multi-variate regression (i.e., when y"
" is a 2d-array of shape [n_samples, n_targets])."
msgstr ""

#: :11
msgid "Read more in the :ref:`User Guide <ridge_regression>`."
msgstr ""

#: :15
msgid "**alpha** : {float, array-like}, shape (n_targets)"
msgstr ""

#: :17
msgid ""
"Small positive values of alpha improve the conditioning of the problem "
"and reduce the variance of the estimates.  Alpha corresponds to ``C^-1`` "
"in other linear models such as LogisticRegression or LinearSVC. If an "
"array is passed, penalties are assumed to be specific to the targets. "
"Hence they must correspond in number."
msgstr ""

#: :23
msgid "**copy_X** : boolean, optional, default True"
msgstr ""

#: :25
msgid "If True, X will be copied; else, it may be overwritten."
msgstr ""

#: :27
msgid "**fit_intercept** : boolean"
msgstr ""

#: :29
msgid ""
"Whether to calculate the intercept for this model. If set to false, no "
"intercept will be used in calculations (e.g. data is expected to be "
"already centered)."
msgstr ""

#: :33
msgid "**max_iter** : int, optional"
msgstr ""

#: :35
msgid ""
"Maximum number of iterations for conjugate gradient solver. For "
"'sparse_cg' and 'lsqr' solvers, the default value is determined by "
"scipy.sparse.linalg. For 'sag' solver, the default value is 1000."
msgstr ""

#: :39
msgid "**normalize** : boolean, optional, default False"
msgstr ""

#: :41
msgid "If True, the regressors X will be normalized before regression."
msgstr ""

#: :43
msgid "**solver** : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag'}"
msgstr ""

#: :45
msgid "Solver to use in the computational routines:"
msgstr ""

#: :47
msgid "'auto' chooses the solver automatically based on the type of data."
msgstr ""

#: :49
msgid ""
"'svd' uses a Singular Value Decomposition of X to compute the Ridge "
"coefficients. More stable for singular matrices than 'cholesky'."
msgstr ""

#: :53
msgid ""
"'cholesky' uses the standard scipy.linalg.solve function to obtain a "
"closed-form solution."
msgstr ""

#: :56
msgid ""
"'sparse_cg' uses the conjugate gradient solver as found in "
"scipy.sparse.linalg.cg. As an iterative algorithm, this solver is more "
"appropriate than 'cholesky' for large-scale data (possibility to set "
"`tol` and `max_iter`)."
msgstr ""

#: :61
msgid ""
"'lsqr' uses the dedicated regularized least-squares routine "
"scipy.sparse.linalg.lsqr. It is the fatest but may not be available in "
"old scipy versions. It also uses an iterative procedure."
msgstr ""

#: :65
msgid ""
"'sag' uses a Stochastic Average Gradient descent. It also uses an "
"iterative procedure, and is often faster than other solvers when both "
"n_samples and n_features are large. Note that 'sag' fast convergence is "
"only guaranteed on features with approximately the same scale. You can "
"preprocess the data with a scaler from sklearn.preprocessing."
msgstr ""

#: :72
msgid ""
"All last four solvers support both dense and sparse data. However, only "
"'sag' supports sparse input when `fit_intercept` is True."
msgstr ""

#: :75
msgid "Stochastic Average Gradient descent solver."
msgstr ""

#: :78
msgid "**tol** : float"
msgstr ""

#: :80
msgid "Precision of the solution."
msgstr ""

#: :82
msgid "**random_state** : int seed, RandomState instance, or None (default)"
msgstr ""

#: :84
msgid ""
"The seed of the pseudo random number generator to use when shuffling the "
"data. Used in 'sag' solver."
msgstr ""

#: :87
msgid "*random_state* to support Stochastic Average Gradient."
msgstr ""

#: :92
msgid "**coef_** : array, shape (n_features,) or (n_targets, n_features)"
msgstr ""

#: :94
msgid "Weight vector(s)."
msgstr ""

#: :96
msgid "**intercept_** : float | array, shape = (n_targets,)"
msgstr ""

#: :98
msgid ""
"Independent term in decision function. Set to 0.0 if ``fit_intercept = "
"False``."
msgstr ""

#: :101
msgid "**n_iter_** : array or None, shape (n_targets,)"
msgstr ""

#: :103
msgid ""
"Actual number of iterations for each target. Available only for sag and "
"lsqr solvers. Other solvers will return None."
msgstr ""

#: :108
msgid ":obj:`RidgeClassifier`, :obj:`RidgeCV`, :obj:`KernelRidge`"
msgstr ""

#: :111
msgid "Examples"
msgstr ""

#: :124
msgid "Methods"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`decision_function <sklearn.linear_model.Ridge.decision_function>`\\"
" (\\*args, \\*\\*kwargs)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "DEPRECATED:  and will be removed in 0.19."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`fit <sklearn.linear_model.Ridge.fit>`\\ (X, y[, sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Fit Ridge regression model"
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`get_params <sklearn.linear_model.Ridge.get_params>`\\ ([deep])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Get parameters for this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`predict <sklearn.linear_model.Ridge.predict>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Predict using the linear model"
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`score <sklearn.linear_model.Ridge.score>`\\ (X, y[, sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Returns the coefficient of determination R^2 of the prediction."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`set_params <sklearn.linear_model.Ridge.set_params>`\\ (\\*\\*params)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Set the parameters of this estimator."
msgstr ""

#: :5
msgid "Decision function of the linear model."
msgstr ""

#: :9 :7
msgid "**X** : {array-like, sparse matrix}, shape = (n_samples, n_features)"
msgstr ""

#: :11 :9
msgid "Samples."
msgstr ""

#: :15 :13
msgid "**C** : array, shape = (n_samples,)"
msgstr ""

#: :17 :15
msgid "Returns predicted values."
msgstr ""

#: :7
msgid "**X** : {array-like, sparse matrix}, shape = [n_samples, n_features]"
msgstr ""

#: :9
msgid "Training data"
msgstr ""

#: :11
msgid "**y** : array-like, shape = [n_samples] or [n_samples, n_targets]"
msgstr ""

#: :13
msgid "Target values"
msgstr ""

#: :15
msgid "**sample_weight** : float or numpy array of shape [n_samples]"
msgstr ""

#: :17
msgid "Individual weights for each sample"
msgstr ""

#: :21
msgid "**self** : returns an instance of self."
msgstr ""

#: :7
msgid "**deep: boolean, optional** :"
msgstr ""

#: :9
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: :14
msgid "**params** : mapping of string to any"
msgstr ""

#: :16
msgid "Parameter names mapped to their values."
msgstr ""

#: :5
msgid ""
"The coefficient R^2 is defined as (1 - u/v), where u is the regression "
"sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual sum "
"of squares ((y_true - y_true.mean()) ** 2).sum(). Best possible score is "
"1.0 and it can be negative (because the model can be arbitrarily worse). "
"A constant model that always predicts the expected value of y, "
"disregarding the input features, would get a R^2 score of 0.0."
msgstr ""

#: :15
msgid "**X** : array-like, shape = (n_samples, n_features)"
msgstr ""

#: :17
msgid "Test samples."
msgstr ""

#: :19
msgid "**y** : array-like, shape = (n_samples) or (n_samples, n_outputs)"
msgstr ""

#: :21
msgid "True values for X."
msgstr ""

#: :23
msgid "**sample_weight** : array-like, shape = [n_samples], optional"
msgstr ""

#: :25
msgid "Sample weights."
msgstr ""

#: :29
msgid "**score** : float"
msgstr ""

#: :31
msgid "R^2 of self.predict(X) wrt. y."
msgstr ""

#: :5
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as pipelines). The former have parameters of the form "
"``<component>__<parameter>`` so that it's possible to update each "
"component of a nested object."
msgstr ""

#: :12
msgid "**self** :"
msgstr ""

#: ../../modules/generated/sklearn.linear_model.Ridge.examples:3
msgid "Examples using ``sklearn.linear_model.Ridge``"
msgstr ""

#: ../../modules/generated/sklearn.linear_model.Ridge.examples:25
msgid ":ref:`example_applications_plot_tomography_l1_reconstruction.py`"
msgstr ""

#: ../../modules/generated/sklearn.linear_model.Ridge.examples:45
msgid ":ref:`example_applications_plot_prediction_latency.py`"
msgstr ""

#: ../../modules/generated/sklearn.linear_model.Ridge.examples:65
msgid ":ref:`example_linear_model_plot_ridge_path.py`"
msgstr ""

#: ../../modules/generated/sklearn.linear_model.Ridge.examples:85
msgid ":ref:`example_linear_model_plot_polynomial_interpolation.py`"
msgstr ""

#: ../../modules/generated/sklearn.linear_model.Ridge.examples:105
msgid ":ref:`example_linear_model_plot_ols_ridge_variance.py`"
msgstr ""

