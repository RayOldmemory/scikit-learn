# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.linear_model.lasso_path.rst:2
msgid ":mod:`sklearn.linear_model`.lasso_path"
msgstr ""

#: :3
msgid "Compute Lasso path with coordinate descent"
msgstr ""

#: :5
msgid "The Lasso optimization function varies for mono and multi-outputs."
msgstr ""

#: :7
msgid "For mono-output tasks it is::"
msgstr ""

#: :11
msgid "For multi-output tasks it is::"
msgstr ""

#: :15
msgid "Where::"
msgstr ""

#: :19
msgid "i.e. the sum of norm of each row."
msgstr ""

#: :21
msgid "Read more in the :ref:`User Guide <lasso>`."
msgstr ""

#: :25
msgid "**X** : {array-like, sparse matrix}, shape (n_samples, n_features)"
msgstr ""

#: :27
msgid ""
"Training data. Pass directly as Fortran-contiguous data to avoid "
"unnecessary memory duplication. If ``y`` is mono-output then ``X`` can be"
" sparse."
msgstr ""

#: :31
msgid "**y** : ndarray, shape (n_samples,), or (n_samples, n_outputs)"
msgstr ""

#: :33
msgid "Target values"
msgstr ""

#: :35
msgid "**eps** : float, optional"
msgstr ""

#: :37
msgid ""
"Length of the path. ``eps=1e-3`` means that ``alpha_min / alpha_max = "
"1e-3``"
msgstr ""

#: :40
msgid "**n_alphas** : int, optional"
msgstr ""

#: :42
msgid "Number of alphas along the regularization path"
msgstr ""

#: :44
msgid "**alphas** : ndarray, optional"
msgstr ""

#: :46
msgid ""
"List of alphas where to compute the models. If ``None`` alphas are set "
"automatically"
msgstr ""

#: :49
msgid "**precompute** : True | False | 'auto' | array-like"
msgstr ""

#: :51
msgid ""
"Whether to use a precomputed Gram matrix to speed up calculations. If set"
" to ``'auto'`` let us decide. The Gram matrix can also be passed as "
"argument."
msgstr ""

#: :55
msgid "**Xy** : array-like, optional"
msgstr ""

#: :57
msgid ""
"Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the "
"Gram matrix is precomputed."
msgstr ""

#: :60
msgid "**copy_X** : boolean, optional, default True"
msgstr ""

#: :62
msgid "If ``True``, X will be copied; else, it may be overwritten."
msgstr ""

#: :64
msgid "**coef_init** : array, shape (n_features, ) | None"
msgstr ""

#: :66
msgid "The initial values of the coefficients."
msgstr ""

#: :68
msgid "**verbose** : bool or integer"
msgstr ""

#: :70
msgid "Amount of verbosity."
msgstr ""

#: :72
msgid "**params** : kwargs"
msgstr ""

#: :74
msgid "keyword arguments passed to the coordinate descent solver."
msgstr ""

#: :76
msgid "**positive** : bool, default False"
msgstr ""

#: :78
msgid "If set to True, forces coefficients to be positive."
msgstr ""

#: :80
msgid "**return_n_iter** : bool"
msgstr ""

#: :82
msgid "whether to return the number of iterations or not."
msgstr ""

#: :86
msgid "**alphas** : array, shape (n_alphas,)"
msgstr ""

#: :88
msgid "The alphas along the path where models are computed."
msgstr ""

#: :90
msgid ""
"**coefs** : array, shape (n_features, n_alphas) or             "
"(n_outputs, n_features, n_alphas)"
msgstr ""

#: :92
msgid "Coefficients along the path."
msgstr ""

#: :94
msgid "**dual_gaps** : array, shape (n_alphas,)"
msgstr ""

#: :96
msgid "The dual gaps at the end of the optimization for each alpha."
msgstr ""

#: :98
msgid "**n_iters** : array-like, shape (n_alphas,)"
msgstr ""

#: :100
msgid ""
"The number of iterations taken by the coordinate descent optimizer to "
"reach the specified tolerance for each alpha."
msgstr ""

#: :105
msgid ""
":obj:`lars_path`, :obj:`Lasso`, :obj:`LassoLars`, :obj:`LassoCV`, "
":obj:`LassoLarsCV`, :obj:`sklearn.decomposition.sparse_encode`"
msgstr ""

#: :108
msgid "Notes"
msgstr ""

#: :109
msgid ""
"See examples/linear_model/plot_lasso_coordinate_descent_path.py for an "
"example."
msgstr ""

#: :112
msgid ""
"To avoid unnecessary memory duplication the X argument of the fit method "
"should be directly passed as a Fortran-contiguous numpy array."
msgstr ""

#: :115
msgid ""
"Note that in certain cases, the Lars solver may be significantly faster "
"to implement this functionality. In particular, linear interpolation can "
"be used to retrieve model coefficients between the values output by "
"lars_path"
msgstr ""

#: :121
msgid "Examples"
msgstr ""

#: :122
msgid "Comparing lasso_path and lars_path with interpolation:"
msgstr ""

#: ../../modules/generated/sklearn.linear_model.lasso_path.examples:3
msgid "Examples using ``sklearn.linear_model.lasso_path``"
msgstr ""

#: ../../modules/generated/sklearn.linear_model.lasso_path.examples:25
msgid ":ref:`example_linear_model_plot_lasso_coordinate_descent_path.py`"
msgstr ""

