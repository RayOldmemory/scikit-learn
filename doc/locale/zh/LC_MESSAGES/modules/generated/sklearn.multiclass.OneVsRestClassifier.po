# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.multiclass.OneVsRestClassifier.rst:2
msgid ":mod:`sklearn.multiclass`.OneVsRestClassifier"
msgstr ""

#: :3
msgid "One-vs-the-rest (OvR) multiclass/multilabel strategy"
msgstr ""

#: :5
msgid ""
"Also known as one-vs-all, this strategy consists in fitting one "
"classifier per class. For each classifier, the class is fitted against "
"all the other classes. In addition to its computational efficiency (only "
"`n_classes` classifiers are needed), one advantage of this approach is "
"its interpretability. Since each class is represented by one and one "
"classifier only, it is possible to gain knowledge about the class by "
"inspecting its corresponding classifier. This is the most commonly used "
"strategy for multiclass classification and is a fair default choice."
msgstr ""

#: :14
msgid ""
"This strategy can also be used for multilabel learning, where a "
"classifier is used to predict multiple labels for instance, by fitting on"
" a 2-d matrix in which cell [i, j] is 1 if sample i has label j and 0 "
"otherwise."
msgstr ""

#: :18
msgid ""
"In the multilabel learning literature, OvR is also known as the binary "
"relevance method."
msgstr ""

#: :21
msgid "Read more in the :ref:`User Guide <ovr_classification>`."
msgstr ""

#: :25
msgid "**estimator** : estimator object"
msgstr ""

#: :27
msgid ""
"An estimator object implementing `fit` and one of `decision_function` or "
"`predict_proba`."
msgstr ""

#: :30
msgid "**n_jobs** : int, optional, default: 1"
msgstr ""

#: :32
msgid ""
"The number of jobs to use for the computation. If -1 all CPUs are used. "
"If 1 is given, no parallel computing code is used at all, which is useful"
" for debugging. For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus"
" for n_jobs = -2, all CPUs but one are used."
msgstr ""

#: :39
msgid "**estimators_** : list of `n_classes` estimators"
msgstr ""

#: :41
msgid "Estimators used for predictions."
msgstr ""

#: :43
msgid "**classes_** : array, shape = [`n_classes`]"
msgstr ""

#: :45
msgid "Class labels."
msgstr ""

#: :47
msgid "**label_binarizer_** : LabelBinarizer object"
msgstr ""

#: :49
msgid ""
"Object used to transform multiclass labels to binary labels and vice-"
"versa."
msgstr ""

#: :52
msgid "**multilabel_** : boolean"
msgstr ""

#: :54
msgid "Whether a OneVsRestClassifier is a multilabel classifier."
msgstr ""

#: :57
msgid "Methods"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`decision_function "
"<sklearn.multiclass.OneVsRestClassifier.decision_function>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1
msgid ""
"Returns the distance of each sample from the decision boundary for each "
"class."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`fit <sklearn.multiclass.OneVsRestClassifier.fit>`\\ (X, y)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Fit underlying estimators."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`get_params <sklearn.multiclass.OneVsRestClassifier.get_params>`\\ "
"([deep])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Get parameters for this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`predict <sklearn.multiclass.OneVsRestClassifier.predict>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Predict multi-class targets using underlying estimators."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`predict_proba "
"<sklearn.multiclass.OneVsRestClassifier.predict_proba>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Probability estimates."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`score <sklearn.multiclass.OneVsRestClassifier.score>`\\ (X, y[, "
"sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Returns the mean accuracy on the given test data and labels."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`set_params <sklearn.multiclass.OneVsRestClassifier.set_params>`\\ "
"(\\*\\*params)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Set the parameters of this estimator."
msgstr ""

#: :3
msgid ""
"Returns the distance of each sample from the decision boundary for each "
"class. This can only be used with estimators which implement the "
"decision_function method."
msgstr ""

#: :9 :17
msgid "**X** : array-like, shape = [n_samples, n_features]"
msgstr ""

#: :13
msgid "**T** : array-like, shape = [n_samples, n_classes]"
msgstr ""

#: :7
msgid "**X** : (sparse) array-like, shape = [n_samples, n_features]"
msgstr ""

#: :9
msgid "Data."
msgstr ""

#: :11
msgid "**y** : (sparse) array-like, shape = [n_samples] or [n_samples, n_classes]"
msgstr ""

#: :13
msgid ""
"Multi-class targets. An indicator matrix turns on multilabel "
"classification."
msgstr ""

#: :18 :12
msgid "**self** :"
msgstr ""

#: :7
msgid "**deep: boolean, optional** :"
msgstr ""

#: :9
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: :14
msgid "**params** : mapping of string to any"
msgstr ""

#: :16
msgid "Parameter names mapped to their values."
msgstr ""

#: :3
msgid "Whether this is a multilabel classifier"
msgstr ""

#: :13
msgid ""
"**y** : (sparse) array-like, shape = [n_samples] or [n_samples, "
"n_classes]."
msgstr ""

#: :15
msgid "Predicted multi-class targets."
msgstr ""

#: :5
msgid "The returned estimates for all classes are ordered by label of classes."
msgstr ""

#: :7
msgid ""
"Note that in the multilabel case, each sample can have any number of "
"labels. This returns the marginal probability that the given sample has "
"the label in question. For example, it is entirely consistent that two "
"labels both have a 90% probability of applying to a given sample."
msgstr ""

#: :12
msgid ""
"In the single label multiclass case, the rows of the returned matrix sum "
"to 1."
msgstr ""

#: :21
msgid "**T** : (sparse) array-like, shape = [n_samples, n_classes]"
msgstr ""

#: :23
msgid ""
"Returns the probability of the sample for each class in the model, where "
"classes are ordered as they are in `self.classes_`."
msgstr ""

#: :5
msgid ""
"In multi-label classification, this is the subset accuracy which is a "
"harsh metric since you require for each sample that each label set be "
"correctly predicted."
msgstr ""

#: :11
msgid "**X** : array-like, shape = (n_samples, n_features)"
msgstr ""

#: :13
msgid "Test samples."
msgstr ""

#: :15
msgid "**y** : array-like, shape = (n_samples) or (n_samples, n_outputs)"
msgstr ""

#: :17
msgid "True labels for X."
msgstr ""

#: :19
msgid "**sample_weight** : array-like, shape = [n_samples], optional"
msgstr ""

#: :21
msgid "Sample weights."
msgstr ""

#: :25
msgid "**score** : float"
msgstr ""

#: :27
msgid "Mean accuracy of self.predict(X) wrt. y."
msgstr ""

#: :5
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as pipelines). The former have parameters of the form "
"``<component>__<parameter>`` so that it's possible to update each "
"component of a nested object."
msgstr ""

#: ../../modules/generated/sklearn.multiclass.OneVsRestClassifier.examples:3
msgid "Examples using ``sklearn.multiclass.OneVsRestClassifier``"
msgstr ""

#: ../../modules/generated/sklearn.multiclass.OneVsRestClassifier.examples:25
msgid ":ref:`example_plot_multilabel.py`"
msgstr ""

#: ../../modules/generated/sklearn.multiclass.OneVsRestClassifier.examples:45
msgid ":ref:`example_model_selection_plot_precision_recall.py`"
msgstr ""

#: ../../modules/generated/sklearn.multiclass.OneVsRestClassifier.examples:65
msgid ":ref:`example_model_selection_plot_roc.py`"
msgstr ""

