# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.naive_bayes.MultinomialNB.rst:2
msgid ":mod:`sklearn.naive_bayes`.MultinomialNB"
msgstr ""

#: :3
msgid "Naive Bayes classifier for multinomial models"
msgstr ""

#: :5
msgid ""
"The multinomial Naive Bayes classifier is suitable for classification "
"with discrete features (e.g., word counts for text classification). The "
"multinomial distribution normally requires integer feature counts. "
"However, in practice, fractional counts such as tf-idf may also work."
msgstr ""

#: :10
msgid "Read more in the :ref:`User Guide <multinomial_naive_bayes>`."
msgstr ""

#: :14
msgid "**alpha** : float, optional (default=1.0)"
msgstr ""

#: :16
msgid "Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing)."
msgstr ""

#: :19
msgid "**fit_prior** : boolean"
msgstr ""

#: :21
msgid ""
"Whether to learn class prior probabilities or not. If false, a uniform "
"prior will be used."
msgstr ""

#: :24
msgid "**class_prior** : array-like, size (n_classes,)"
msgstr ""

#: :26
msgid ""
"Prior probabilities of the classes. If specified the priors are not "
"adjusted according to the data."
msgstr ""

#: :31
msgid "**class_log_prior_** : array, shape (n_classes, )"
msgstr ""

#: :33
msgid "Smoothed empirical log probability for each class."
msgstr ""

#: :35
msgid "**intercept_** : property"
msgstr ""

#: :37
msgid ""
"Mirrors ``class_log_prior_`` for interpreting MultinomialNB as a linear "
"model."
msgstr ""

#: :40
msgid "**feature_log_prob_** : array, shape (n_classes, n_features)"
msgstr ""

#: :42
msgid "Empirical log probability of features given a class, ``P(x_i|y)``."
msgstr ""

#: :45
msgid "**coef_** : property"
msgstr ""

#: :47
msgid ""
"Mirrors ``feature_log_prob_`` for interpreting MultinomialNB as a linear "
"model."
msgstr ""

#: :50
msgid "**class_count_** : array, shape (n_classes,)"
msgstr ""

#: :52
msgid ""
"Number of samples encountered for each class during fitting. This value "
"is weighted by the sample weight when provided."
msgstr ""

#: :55
msgid "**feature_count_** : array, shape (n_classes, n_features)"
msgstr ""

#: :57
msgid ""
"Number of samples encountered for each (class, feature) during fitting. "
"This value is weighted by the sample weight when provided."
msgstr ""

#: :62
msgid "Notes"
msgstr ""

#: :63
msgid ""
"For the rationale behind the names `coef_` and `intercept_`, i.e. naive "
"Bayes as a linear classifier, see J. Rennie et al. (2003), Tackling the "
"poor assumptions of naive Bayes text classifiers, ICML."
msgstr ""

#: :68
msgid "References"
msgstr ""

#: :69
msgid ""
"C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to "
"Information Retrieval. Cambridge University Press, pp. 234-265. "
"http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-"
"classification-1.html"
msgstr ""

#: :76
msgid "Examples"
msgstr ""

#: :88
msgid "Methods"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`fit <sklearn.naive_bayes.MultinomialNB.fit>`\\ (X, y[, "
"sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Fit Naive Bayes classifier according to X, y"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`get_params <sklearn.naive_bayes.MultinomialNB.get_params>`\\ "
"([deep])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Get parameters for this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`partial_fit <sklearn.naive_bayes.MultinomialNB.partial_fit>`\\ (X, "
"y[, classes, sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Incremental fit on a batch of samples."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`predict <sklearn.naive_bayes.MultinomialNB.predict>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Perform classification on an array of test vectors X."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`predict_log_proba "
"<sklearn.naive_bayes.MultinomialNB.predict_log_proba>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Return log-probability estimates for the test vector X."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`predict_proba <sklearn.naive_bayes.MultinomialNB.predict_proba>`\\ "
"(X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Return probability estimates for the test vector X."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`score <sklearn.naive_bayes.MultinomialNB.score>`\\ (X, y[, "
"sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Returns the mean accuracy on the given test data and labels."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`set_params <sklearn.naive_bayes.MultinomialNB.set_params>`\\ "
"(\\*\\*params)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Set the parameters of this estimator."
msgstr ""

#: :7 :18
msgid "**X** : {array-like, sparse matrix}, shape = [n_samples, n_features]"
msgstr ""

#: :9 :20
msgid ""
"Training vectors, where n_samples is the number of samples and n_features"
" is the number of features."
msgstr ""

#: :12 :23
msgid "**y** : array-like, shape = [n_samples]"
msgstr ""

#: :14 :25
msgid "Target values."
msgstr ""

#: :16 :34 :19
msgid "**sample_weight** : array-like, shape = [n_samples], optional"
msgstr ""

#: :18 :36
msgid "Weights applied to individual samples (1. for unweighted)."
msgstr ""

#: :22 :40
msgid "**self** : object"
msgstr ""

#: :24 :42
msgid "Returns self."
msgstr ""

#: :7
msgid "**deep: boolean, optional** :"
msgstr ""

#: :9
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: :14
msgid "**params** : mapping of string to any"
msgstr ""

#: :16
msgid "Parameter names mapped to their values."
msgstr ""

#: :5
msgid ""
"This method is expected to be called several times consecutively on "
"different chunks of a dataset so as to implement out-of-core or online "
"learning."
msgstr ""

#: :9
msgid ""
"This is especially useful when the whole dataset is too big to fit in "
"memory at once."
msgstr ""

#: :12
msgid ""
"This method has some performance overhead hence it is better to call "
"partial_fit on chunks of data that are as large as possible (as long as "
"fitting in the memory budget) to hide the overhead."
msgstr ""

#: :27
msgid "**classes** : array-like, shape = [n_classes]"
msgstr ""

#: :29
msgid "List of all the classes that can possibly appear in the y vector."
msgstr ""

#: :31
msgid ""
"Must be provided at the first call to partial_fit, can be omitted in "
"subsequent calls."
msgstr ""

#: :7
msgid "**X** : array-like, shape = [n_samples, n_features]"
msgstr ""

#: :11
msgid "**C** : array, shape = [n_samples]"
msgstr ""

#: :13
msgid "Predicted target values for X"
msgstr ""

#: :11
msgid "**C** : array-like, shape = [n_samples, n_classes]"
msgstr ""

#: :13
msgid ""
"Returns the log-probability of the samples for each class in the model. "
"The columns correspond to the classes in sorted order, as they appear in "
"the attribute `classes_`."
msgstr ""

#: :13
msgid ""
"Returns the probability of the samples for each class in the model. The "
"columns correspond to the classes in sorted order, as they appear in the "
"attribute `classes_`."
msgstr ""

#: :5
msgid ""
"In multi-label classification, this is the subset accuracy which is a "
"harsh metric since you require for each sample that each label set be "
"correctly predicted."
msgstr ""

#: :11
msgid "**X** : array-like, shape = (n_samples, n_features)"
msgstr ""

#: :13
msgid "Test samples."
msgstr ""

#: :15
msgid "**y** : array-like, shape = (n_samples) or (n_samples, n_outputs)"
msgstr ""

#: :17
msgid "True labels for X."
msgstr ""

#: :21
msgid "Sample weights."
msgstr ""

#: :25
msgid "**score** : float"
msgstr ""

#: :27
msgid "Mean accuracy of self.predict(X) wrt. y."
msgstr ""

#: :5
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as pipelines). The former have parameters of the form "
"``<component>__<parameter>`` so that it's possible to update each "
"component of a nested object."
msgstr ""

#: :12
msgid "**self** :"
msgstr ""

#: ../../modules/generated/sklearn.naive_bayes.MultinomialNB.examples:3
msgid "Examples using ``sklearn.naive_bayes.MultinomialNB``"
msgstr ""

#: ../../modules/generated/sklearn.naive_bayes.MultinomialNB.examples:25
msgid ":ref:`example_applications_plot_out_of_core_classification.py`"
msgstr ""

#: ../../modules/generated/sklearn.naive_bayes.MultinomialNB.examples:45
msgid ":ref:`example_text_mlcomp_sparse_document_classification.py`"
msgstr ""

#: ../../modules/generated/sklearn.naive_bayes.MultinomialNB.examples:65
msgid ":ref:`example_text_document_classification_20newsgroups.py`"
msgstr ""

