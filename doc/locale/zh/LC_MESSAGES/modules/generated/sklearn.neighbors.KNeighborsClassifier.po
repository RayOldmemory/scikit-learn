# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.neighbors.KNeighborsClassifier.rst:2
msgid ":mod:`sklearn.neighbors`.KNeighborsClassifier"
msgstr ""

#: :3
msgid "Classifier implementing the k-nearest neighbors vote."
msgstr ""

#: :5
msgid "Read more in the :ref:`User Guide <classification>`."
msgstr ""

#: :9
msgid "**n_neighbors** : int, optional (default = 5)"
msgstr ""

#: :11
msgid "Number of neighbors to use by default for :meth:`k_neighbors` queries."
msgstr ""

#: :13
msgid "**weights** : str or callable"
msgstr ""

#: :15
msgid "weight function used in prediction.  Possible values:"
msgstr ""

#: :17
msgid ""
"'uniform' : uniform weights.  All points in each neighborhood are "
"weighted equally."
msgstr ""

#: :19
msgid ""
"'distance' : weight points by the inverse of their distance. in this "
"case, closer neighbors of a query point will have a greater influence "
"than neighbors which are further away."
msgstr ""

#: :22
msgid ""
"[callable] : a user-defined function which accepts an array of distances,"
" and returns an array of the same shape containing the weights."
msgstr ""

#: :26
msgid "Uniform weights are used by default."
msgstr ""

#: :28
msgid "**algorithm** : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional"
msgstr ""

#: :30
msgid "Algorithm used to compute the nearest neighbors:"
msgstr ""

#: :32
msgid "'ball_tree' will use :class:`BallTree`"
msgstr ""

#: :33
msgid "'kd_tree' will use :class:`KDTree`"
msgstr ""

#: :34
msgid "'brute' will use a brute-force search."
msgstr ""

#: :35
msgid ""
"'auto' will attempt to decide the most appropriate algorithm based on the"
" values passed to :meth:`fit` method."
msgstr ""

#: :38
msgid ""
"Note: fitting on sparse input will override the setting of this "
"parameter, using brute force."
msgstr ""

#: :41
msgid "**leaf_size** : int, optional (default = 30)"
msgstr ""

#: :43
msgid ""
"Leaf size passed to BallTree or KDTree.  This can affect the speed of the"
" construction and query, as well as the memory required to store the "
"tree.  The optimal value depends on the nature of the problem."
msgstr ""

#: :48
msgid "**metric** : string or DistanceMetric object (default = 'minkowski')"
msgstr ""

#: :50
msgid ""
"the distance metric to use for the tree.  The default metric is "
"minkowski, and with p=2 is equivalent to the standard Euclidean metric. "
"See the documentation of the DistanceMetric class for a list of available"
" metrics."
msgstr ""

#: :55
msgid "**p** : integer, optional (default = 2)"
msgstr ""

#: :57
msgid ""
"Power parameter for the Minkowski metric. When p = 1, this is equivalent "
"to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. "
"For arbitrary p, minkowski_distance (l_p) is used."
msgstr ""

#: :61
msgid "**metric_params** : dict, optional (default = None)"
msgstr ""

#: :63
msgid "Additional keyword arguments for the metric function."
msgstr ""

#: :65
msgid "**n_jobs** : int, optional (default = 1)"
msgstr ""

#: :67
msgid ""
"The number of parallel jobs to run for neighbors search. If ``-1``, then "
"the number of jobs is set to the number of CPU cores. Doesn't affect "
":meth:`fit` method."
msgstr ""

#: :73
msgid ""
":obj:`RadiusNeighborsClassifier`, :obj:`KNeighborsRegressor`, "
":obj:`RadiusNeighborsRegressor`, :obj:`NearestNeighbors`"
msgstr ""

#: :76
msgid "Notes"
msgstr ""

#: :77
msgid ""
"See :ref:`Nearest Neighbors <neighbors>` in the online documentation for "
"a discussion of the choice of ``algorithm`` and ``leaf_size``."
msgstr ""

#: :82
msgid ""
"Regarding the Nearest Neighbors algorithms, if it is found that two "
"neighbors, neighbor `k+1` and `k`, have identical distances but but "
"different labels, the results will depend on the ordering of the training"
" data."
msgstr ""

#: :87
msgid "http://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm"
msgstr ""

#: :90 :36
msgid "Examples"
msgstr ""

#: :103
msgid "Methods"
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`fit <sklearn.neighbors.KNeighborsClassifier.fit>`\\ (X, y)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Fit the model using X as training data and y as target values"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`get_params <sklearn.neighbors.KNeighborsClassifier.get_params>`\\ "
"([deep])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Get parameters for this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`kneighbors <sklearn.neighbors.KNeighborsClassifier.kneighbors>`\\ "
"([X, n_neighbors, return_distance])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Finds the K-neighbors of a point."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`kneighbors_graph "
"<sklearn.neighbors.KNeighborsClassifier.kneighbors_graph>`\\ ([X, "
"n_neighbors, mode])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Computes the (weighted) graph of k-Neighbors for points in X"
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`predict <sklearn.neighbors.KNeighborsClassifier.predict>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Predict the class labels for the provided data"
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`predict_proba "
"<sklearn.neighbors.KNeighborsClassifier.predict_proba>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Return probability estimates for the test data X."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`score <sklearn.neighbors.KNeighborsClassifier.score>`\\ (X, y[, "
"sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Returns the mean accuracy on the given test data and labels."
msgstr ""

#: ../../<autosummary>:1
msgid ""
":obj:`set_params <sklearn.neighbors.KNeighborsClassifier.set_params>`\\ "
"(\\*\\*params)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Set the parameters of this estimator."
msgstr ""

#: :7
msgid "**X** : {array-like, sparse matrix, BallTree, KDTree}"
msgstr ""

#: :9
msgid ""
"Training data. If array or matrix, shape [n_samples, n_features], or "
"[n_samples, n_samples] if metric='precomputed'."
msgstr ""

#: :12
msgid "**y** : {array-like, sparse matrix}"
msgstr ""

#: :14
msgid "Target values of shape = [n_samples] or [n_samples, n_outputs]"
msgstr ""

#: :7
msgid "**deep: boolean, optional** :"
msgstr ""

#: :9
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: :14
msgid "**params** : mapping of string to any"
msgstr ""

#: :16
msgid "Parameter names mapped to their values."
msgstr ""

#: :5
msgid "Returns indices of and distances to the neighbors of each point."
msgstr ""

#: :9 :7
msgid ""
"**X** : array-like, shape (n_query, n_features),                 or "
"(n_query, n_indexed) if metric == 'precomputed'"
msgstr ""

#: :11 :9
msgid ""
"The query point or points. If not provided, neighbors of each indexed "
"point are returned. In this case, the query point is not considered its "
"own neighbor."
msgstr ""

#: :15 :13
msgid "**n_neighbors** : int"
msgstr ""

#: :17
msgid ""
"Number of neighbors to get (default is the value passed to the "
"constructor)."
msgstr ""

#: :20
msgid "**return_distance** : boolean, optional. Defaults to True."
msgstr ""

#: :22
msgid "If False, distances will not be returned"
msgstr ""

#: :26
msgid "**dist** : array"
msgstr ""

#: :28
msgid ""
"Array representing the lengths to points, only present if "
"return_distance=True"
msgstr ""

#: :31
msgid "**ind** : array"
msgstr ""

#: :33
msgid "Indices of the nearest points in the population matrix."
msgstr ""

#: :37
msgid ""
"In the following example, we construct a NeighborsClassifier class from "
"an array representing our data set and ask who's the closest point to "
"[1,1,1]"
msgstr ""

#: :49
msgid ""
"As you can see, it returns [[0.5]], and [[2]], which means that the "
"element is at distance 0.5 and is the third element of samples (indexes "
"start at 0). You can also query for multiple points:"
msgstr ""

#: :15
msgid ""
"Number of neighbors for each sample. (default is value passed to the "
"constructor)."
msgstr ""

#: :18
msgid "**mode** : {'connectivity', 'distance'}, optional"
msgstr ""

#: :20
msgid ""
"Type of returned matrix: 'connectivity' will return the connectivity "
"matrix with ones and zeros, in 'distance' the edges are Euclidean "
"distance between points."
msgstr ""

#: :26
msgid "**A** : sparse matrix in CSR format, shape = [n_samples, n_samples_fit]"
msgstr ""

#: :28
msgid ""
"n_samples_fit is the number of samples in the fitted data A[i, j] is "
"assigned the weight of edge that connects i to j."
msgstr ""

#: :33
msgid ":obj:`NearestNeighbors.radius_neighbors_graph`"
msgstr ""

#: :9 :13
msgid "Test samples."
msgstr ""

#: :13
msgid "**y** : array of shape [n_samples] or [n_samples, n_outputs]"
msgstr ""

#: :15
msgid "Class labels for each data sample."
msgstr ""

#: :13
msgid "**p** : array of shape = [n_samples, n_classes], or a list of n_outputs"
msgstr ""

#: :15
msgid ""
"of such arrays if n_outputs > 1. The class probabilities of the input "
"samples. Classes are ordered by lexicographic order."
msgstr ""

#: :5
msgid ""
"In multi-label classification, this is the subset accuracy which is a "
"harsh metric since you require for each sample that each label set be "
"correctly predicted."
msgstr ""

#: :11
msgid "**X** : array-like, shape = (n_samples, n_features)"
msgstr ""

#: :15
msgid "**y** : array-like, shape = (n_samples) or (n_samples, n_outputs)"
msgstr ""

#: :17
msgid "True labels for X."
msgstr ""

#: :19
msgid "**sample_weight** : array-like, shape = [n_samples], optional"
msgstr ""

#: :21
msgid "Sample weights."
msgstr ""

#: :25
msgid "**score** : float"
msgstr ""

#: :27
msgid "Mean accuracy of self.predict(X) wrt. y."
msgstr ""

#: :5
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as pipelines). The former have parameters of the form "
"``<component>__<parameter>`` so that it's possible to update each "
"component of a nested object."
msgstr ""

#: :12
msgid "**self** :"
msgstr ""

#: ../../modules/generated/sklearn.neighbors.KNeighborsClassifier.examples:3
msgid "Examples using ``sklearn.neighbors.KNeighborsClassifier``"
msgstr ""

#: ../../modules/generated/sklearn.neighbors.KNeighborsClassifier.examples:25
msgid ":ref:`example_classification_plot_classifier_comparison.py`"
msgstr ""

#: ../../modules/generated/sklearn.neighbors.KNeighborsClassifier.examples:45
msgid ":ref:`example_ensemble_plot_voting_decision_regions.py`"
msgstr ""

#: ../../modules/generated/sklearn.neighbors.KNeighborsClassifier.examples:65
msgid ":ref:`example_exercises_digits_classification_exercise.py`"
msgstr ""

#: ../../modules/generated/sklearn.neighbors.KNeighborsClassifier.examples:85
msgid ":ref:`example_neighbors_plot_classification.py`"
msgstr ""

#: ../../modules/generated/sklearn.neighbors.KNeighborsClassifier.examples:105
msgid ":ref:`example_preprocessing_plot_robust_scaling.py`"
msgstr ""

#: ../../modules/generated/sklearn.neighbors.KNeighborsClassifier.examples:125
msgid ":ref:`example_text_document_classification_20newsgroups.py`"
msgstr ""

