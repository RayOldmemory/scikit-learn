# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.svm.NuSVC.rst:2
msgid ":mod:`sklearn.svm`.NuSVC"
msgstr ""

#: :3
msgid "Nu-Support Vector Classification."
msgstr ""

#: :5
msgid ""
"Similar to SVC but uses a parameter to control the number of support "
"vectors."
msgstr ""

#: :8
msgid "The implementation is based on libsvm."
msgstr ""

#: :10
msgid "Read more in the :ref:`User Guide <svm_classification>`."
msgstr ""

#: :14
msgid "**nu** : float, optional (default=0.5)"
msgstr ""

#: :16
msgid ""
"An upper bound on the fraction of training errors and a lower bound of "
"the fraction of support vectors. Should be in the interval (0, 1]."
msgstr ""

#: :20
msgid "**kernel** : string, optional (default='rbf')"
msgstr ""

#: :22
msgid ""
"Specifies the kernel type to be used in the algorithm. It must be one of "
"'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or a callable. If none "
"is given, 'rbf' will be used. If a callable is given it is used to "
"precompute the kernel matrix."
msgstr ""

#: :28
msgid "**degree** : int, optional (default=3)"
msgstr ""

#: :30
msgid ""
"Degree of the polynomial kernel function ('poly'). Ignored by all other "
"kernels."
msgstr ""

#: :33
msgid "**gamma** : float, optional (default='auto')"
msgstr ""

#: :35
msgid ""
"Kernel coefficient for 'rbf', 'poly' and 'sigmoid'. If gamma is 'auto' "
"then 1/n_features will be used instead."
msgstr ""

#: :38
msgid "**coef0** : float, optional (default=0.0)"
msgstr ""

#: :40
msgid ""
"Independent term in kernel function. It is only significant in 'poly' and"
" 'sigmoid'."
msgstr ""

#: :43
msgid "**probability** : boolean, optional (default=False)"
msgstr ""

#: :45
msgid ""
"Whether to enable probability estimates. This must be enabled prior to "
"calling `fit`, and will slow down that method."
msgstr ""

#: :48
msgid "**shrinking** : boolean, optional (default=True)"
msgstr ""

#: :50
msgid "Whether to use the shrinking heuristic."
msgstr ""

#: :52
msgid "**tol** : float, optional (default=1e-3)"
msgstr ""

#: :54
msgid "Tolerance for stopping criterion."
msgstr ""

#: :56
msgid "**cache_size** : float, optional"
msgstr ""

#: :58
msgid "Specify the size of the kernel cache (in MB)."
msgstr ""

#: :60
msgid "**class_weight** : {dict, 'auto'}, optional"
msgstr ""

#: :62
msgid ""
"Set the parameter C of class i to class_weight[i]*C for SVC. If not "
"given, all classes are supposed to have weight one. The 'auto' mode uses "
"the values of y to automatically adjust weights inversely proportional to"
" class frequencies."
msgstr ""

#: :68
msgid "**verbose** : bool, default: False"
msgstr ""

#: :70
msgid ""
"Enable verbose output. Note that this setting takes advantage of a per-"
"process runtime setting in libsvm that, if enabled, may not work properly"
" in a multithreaded context."
msgstr ""

#: :74
msgid "**max_iter** : int, optional (default=-1)"
msgstr ""

#: :76
msgid "Hard limit on iterations within solver, or -1 for no limit."
msgstr ""

#: :78
msgid "**decision_function_shape** : 'ovo', 'ovr' or None, default=None"
msgstr ""

#: :80
msgid ""
"Whether to return a one-vs-rest ('ovr') ecision function of shape "
"(n_samples, n_classes) as all other classifiers, or the original one-vs-"
"one ('ovo') decision function of libsvm which has shape (n_samples, "
"n_classes * (n_classes - 1) / 2). The default of None will currently "
"behave as 'ovo' for backward compatibility and raise a deprecation "
"warning, but will change 'ovr' in 0.18."
msgstr ""

#: :88
msgid "*decision_function_shape='ovr'* is recommended."
msgstr ""

#: :91
msgid "Deprecated *decision_function_shape='ovo' and None*."
msgstr ""

#: :94
msgid "**random_state** : int seed, RandomState instance, or None (default)"
msgstr ""

#: :96
msgid ""
"The seed of the pseudo random number generator to use when shuffling the "
"data for probability estimation."
msgstr ""

#: :101
msgid "**support_** : array-like, shape = [n_SV]"
msgstr ""

#: :103
msgid "Indices of support vectors."
msgstr ""

#: :105
msgid "**support_vectors_** : array-like, shape = [n_SV, n_features]"
msgstr ""

#: :107
msgid "Support vectors."
msgstr ""

#: :109
msgid "**n_support_** : array-like, dtype=int32, shape = [n_class]"
msgstr ""

#: :111
msgid "Number of support vectors for each class."
msgstr ""

#: :113
msgid "**dual_coef_** : array, shape = [n_class-1, n_SV]"
msgstr ""

#: :115
msgid ""
"Coefficients of the support vector in the decision function. For "
"multiclass, coefficient for all 1-vs-1 classifiers. The layout of the "
"coefficients in the multiclass case is somewhat non-trivial. See the "
"section about multi-class classification in the SVM section of the User "
"Guide for details."
msgstr ""

#: :121
msgid "**coef_** : array, shape = [n_class-1, n_features]"
msgstr ""

#: :123
msgid ""
"Weights assigned to the features (coefficients in the primal problem). "
"This is only available in the case of a linear kernel."
msgstr ""

#: :126
msgid ""
"`coef_` is readonly property derived from `dual_coef_` and "
"`support_vectors_`."
msgstr ""

#: :129
msgid "**intercept_** : array, shape = [n_class * (n_class-1) / 2]"
msgstr ""

#: :131
msgid "Constants in decision function."
msgstr ""

#: :136
msgid ":obj:`SVC`"
msgstr ""

#: :136
msgid "Support Vector Machine for classification using libsvm."
msgstr ""

#: :138
msgid ":obj:`LinearSVC`"
msgstr ""

#: :139
msgid "Scalable linear Support Vector Machine for classification using liblinear."
msgstr ""

#: :142
msgid "Examples"
msgstr ""

#: :157
msgid "Methods"
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`decision_function <sklearn.svm.NuSVC.decision_function>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Distance of the samples X to the separating hyperplane."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`fit <sklearn.svm.NuSVC.fit>`\\ (X, y[, sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Fit the SVM model according to the given training data."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`get_params <sklearn.svm.NuSVC.get_params>`\\ ([deep])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Get parameters for this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`predict <sklearn.svm.NuSVC.predict>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Perform classification on samples in X."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`score <sklearn.svm.NuSVC.score>`\\ (X, y[, sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Returns the mean accuracy on the given test data and labels."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`set_params <sklearn.svm.NuSVC.set_params>`\\ (\\*\\*params)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Set the parameters of this estimator."
msgstr ""

#: :7 :10
msgid "**X** : array-like, shape (n_samples, n_features)"
msgstr ""

#: :11
msgid "**X** : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)"
msgstr ""

#: :13
msgid ""
"Returns the decision function of the sample for each class in the model. "
"If decision_function_shape='ovr', the shape is (n_samples, n_classes)"
msgstr ""

#: :7 :9
msgid "**X** : {array-like, sparse matrix}, shape (n_samples, n_features)"
msgstr ""

#: :9
msgid ""
"Training vectors, where n_samples is the number of samples and n_features"
" is the number of features. For kernel=\"precomputed\", the expected "
"shape of X is (n_samples, n_samples)."
msgstr ""

#: :14
msgid "**y** : array-like, shape (n_samples,)"
msgstr ""

#: :16
msgid "Target values (class labels in classification, real numbers in regression)"
msgstr ""

#: :19
msgid "**sample_weight** : array-like, shape (n_samples,)"
msgstr ""

#: :21
msgid ""
"Per-sample weights. Rescale C per sample. Higher weights force the "
"classifier to put more emphasis on these points."
msgstr ""

#: :26
msgid "**self** : object"
msgstr ""

#: :28
msgid "Returns self."
msgstr ""

#: :31 :24
msgid "Notes"
msgstr ""

#: :32
msgid ""
"If X and y are not C-ordered and contiguous arrays of np.float64 and X is"
" not a scipy.sparse.csr_matrix, X and/or y may be copied."
msgstr ""

#: :35
msgid ""
"If X is a dense array, then the other methods will not support sparse "
"matrices as input."
msgstr ""

#: :7
msgid "**deep: boolean, optional** :"
msgstr ""

#: :9
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: :14
msgid "**params** : mapping of string to any"
msgstr ""

#: :16
msgid "Parameter names mapped to their values."
msgstr ""

#: :5
msgid "For an one-class model, +1 or -1 is returned."
msgstr ""

#: :11 :12
msgid ""
"For kernel=\"precomputed\", the expected shape of X is [n_samples_test, "
"n_samples_train]"
msgstr ""

#: :16
msgid "**y_pred** : array, shape (n_samples,)"
msgstr ""

#: :18
msgid "Class labels for samples in X."
msgstr ""

#: :3
msgid "Compute log probabilities of possible outcomes for samples in X."
msgstr ""

#: :5
msgid ""
"The model need to have probability information computed at training time:"
" fit with attribute `probability` set to True."
msgstr ""

#: :17
msgid "**T** : array-like, shape (n_samples, n_classes)"
msgstr ""

#: :19
msgid ""
"Returns the log-probabilities of the sample for each class in the model. "
"The columns correspond to the classes in sorted order, as they appear in "
"the attribute `classes_`."
msgstr ""

#: :25
msgid ""
"The probability model is created using cross validation, so the results "
"can be slightly different than those obtained by predict. Also, it will "
"produce meaningless results on very small datasets."
msgstr ""

#: :3
msgid "Compute probabilities of possible outcomes for samples in X."
msgstr ""

#: :19
msgid ""
"Returns the probability of the sample for each class in the model. The "
"columns correspond to the classes in sorted order, as they appear in the "
"attribute `classes_`."
msgstr ""

#: :5
msgid ""
"In multi-label classification, this is the subset accuracy which is a "
"harsh metric since you require for each sample that each label set be "
"correctly predicted."
msgstr ""

#: :11
msgid "**X** : array-like, shape = (n_samples, n_features)"
msgstr ""

#: :13
msgid "Test samples."
msgstr ""

#: :15
msgid "**y** : array-like, shape = (n_samples) or (n_samples, n_outputs)"
msgstr ""

#: :17
msgid "True labels for X."
msgstr ""

#: :19
msgid "**sample_weight** : array-like, shape = [n_samples], optional"
msgstr ""

#: :21
msgid "Sample weights."
msgstr ""

#: :25
msgid "**score** : float"
msgstr ""

#: :27
msgid "Mean accuracy of self.predict(X) wrt. y."
msgstr ""

#: :5
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as pipelines). The former have parameters of the form "
"``<component>__<parameter>`` so that it's possible to update each "
"component of a nested object."
msgstr ""

#: :12
msgid "**self** :"
msgstr ""

#: ../../modules/generated/sklearn.svm.NuSVC.examples:3
msgid "Examples using ``sklearn.svm.NuSVC``"
msgstr ""

#: ../../modules/generated/sklearn.svm.NuSVC.examples:25
msgid ":ref:`example_svm_plot_svm_nonlinear.py`"
msgstr ""

