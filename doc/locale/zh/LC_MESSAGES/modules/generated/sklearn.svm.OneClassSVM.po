# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.svm.OneClassSVM.rst:2
msgid ":mod:`sklearn.svm`.OneClassSVM"
msgstr ""

#: :3
msgid "Unsupervised Outlier Detection."
msgstr ""

#: :5
msgid "Estimate the support of a high-dimensional distribution."
msgstr ""

#: :7
msgid "The implementation is based on libsvm."
msgstr ""

#: :9
msgid "Read more in the :ref:`User Guide <svm_outlier_detection>`."
msgstr ""

#: :13
msgid "**kernel** : string, optional (default='rbf')"
msgstr ""

#: :15
msgid ""
"Specifies the kernel type to be used in the algorithm. It must be one of "
"'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or a callable. If none "
"is given, 'rbf' will be used. If a callable is given it is used to "
"precompute the kernel matrix."
msgstr ""

#: :21
msgid "**nu** : float, optional"
msgstr ""

#: :23
msgid ""
"An upper bound on the fraction of training errors and a lower bound of "
"the fraction of support vectors. Should be in the interval (0, 1]. By "
"default 0.5 will be taken."
msgstr ""

#: :28
msgid "**degree** : int, optional (default=3)"
msgstr ""

#: :30
msgid ""
"Degree of the polynomial kernel function ('poly'). Ignored by all other "
"kernels."
msgstr ""

#: :33
msgid "**gamma** : float, optional (default='auto')"
msgstr ""

#: :35
msgid ""
"Kernel coefficient for 'rbf', 'poly' and 'sigmoid'. If gamma is 'auto' "
"then 1/n_features will be used instead."
msgstr ""

#: :38
msgid "**coef0** : float, optional (default=0.0)"
msgstr ""

#: :40
msgid ""
"Independent term in kernel function. It is only significant in 'poly' and"
" 'sigmoid'."
msgstr ""

#: :43
msgid "**tol** : float, optional"
msgstr ""

#: :45
msgid "Tolerance for stopping criterion."
msgstr ""

#: :47
msgid "**shrinking** : boolean, optional"
msgstr ""

#: :49
msgid "Whether to use the shrinking heuristic."
msgstr ""

#: :51
msgid "**cache_size** : float, optional"
msgstr ""

#: :53
msgid "Specify the size of the kernel cache (in MB)."
msgstr ""

#: :55
msgid "**verbose** : bool, default: False"
msgstr ""

#: :57
msgid ""
"Enable verbose output. Note that this setting takes advantage of a per-"
"process runtime setting in libsvm that, if enabled, may not work properly"
" in a multithreaded context."
msgstr ""

#: :61
msgid "**max_iter** : int, optional (default=-1)"
msgstr ""

#: :63
msgid "Hard limit on iterations within solver, or -1 for no limit."
msgstr ""

#: :65
msgid "**random_state** : int seed, RandomState instance, or None (default)"
msgstr ""

#: :67
msgid ""
"The seed of the pseudo random number generator to use when shuffling the "
"data for probability estimation."
msgstr ""

#: :72
msgid "**support_** : array-like, shape = [n_SV]"
msgstr ""

#: :74
msgid "Indices of support vectors."
msgstr ""

#: :76
msgid "**support_vectors_** : array-like, shape = [nSV, n_features]"
msgstr ""

#: :78
msgid "Support vectors."
msgstr ""

#: :80
msgid "**dual_coef_** : array, shape = [n_classes-1, n_SV]"
msgstr ""

#: :82
msgid "Coefficients of the support vectors in the decision function."
msgstr ""

#: :84
msgid "**coef_** : array, shape = [n_classes-1, n_features]"
msgstr ""

#: :86
msgid ""
"Weights assigned to the features (coefficients in the primal problem). "
"This is only available in the case of a linear kernel."
msgstr ""

#: :89
msgid ""
"`coef_` is readonly property derived from `dual_coef_` and "
"`support_vectors_`"
msgstr ""

#: :92
msgid "**intercept_** : array, shape = [n_classes-1]"
msgstr ""

#: :94
msgid "Constants in decision function."
msgstr ""

#: :97
msgid "Methods"
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`decision_function <sklearn.svm.OneClassSVM.decision_function>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Distance of the samples X to the separating hyperplane."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`fit <sklearn.svm.OneClassSVM.fit>`\\ (X[, y, sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Detects the soft boundary of the set of samples X."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`get_params <sklearn.svm.OneClassSVM.get_params>`\\ ([deep])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Get parameters for this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`predict <sklearn.svm.OneClassSVM.predict>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Perform regression on samples in X."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`set_params <sklearn.svm.OneClassSVM.set_params>`\\ (\\*\\*params)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Set the parameters of this estimator."
msgstr ""

#: :7
msgid "**X** : array-like, shape (n_samples, n_features)"
msgstr ""

#: :11
msgid "**X** : array-like, shape (n_samples,)"
msgstr ""

#: :13
msgid "Returns the decision function of the samples."
msgstr ""

#: :7 :9
msgid "**X** : {array-like, sparse matrix}, shape (n_samples, n_features)"
msgstr ""

#: :9
msgid ""
"Set of samples, where n_samples is the number of samples and n_features "
"is the number of features."
msgstr ""

#: :12
msgid "**sample_weight** : array-like, shape (n_samples,)"
msgstr ""

#: :14
msgid ""
"Per-sample weights. Rescale C per sample. Higher weights force the "
"classifier to put more emphasis on these points."
msgstr ""

#: :19
msgid "**self** : object"
msgstr ""

#: :21
msgid "Returns self."
msgstr ""

#: :24
msgid "Notes"
msgstr ""

#: :25
msgid "If X is not a C-ordered contiguous array it is copied."
msgstr ""

#: :7
msgid "**deep: boolean, optional** :"
msgstr ""

#: :9
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: :14
msgid "**params** : mapping of string to any"
msgstr ""

#: :16
msgid "Parameter names mapped to their values."
msgstr ""

#: :5
msgid "For an one-class model, +1 or -1 is returned."
msgstr ""

#: :11
msgid ""
"For kernel=\"precomputed\", the expected shape of X is (n_samples_test, "
"n_samples_train)."
msgstr ""

#: :16
msgid "**y_pred** : array, shape (n_samples,)"
msgstr ""

#: :5
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as pipelines). The former have parameters of the form "
"``<component>__<parameter>`` so that it's possible to update each "
"component of a nested object."
msgstr ""

#: :12
msgid "**self** :"
msgstr ""

#: ../../modules/generated/sklearn.svm.OneClassSVM.examples:3
msgid "Examples using ``sklearn.svm.OneClassSVM``"
msgstr ""

#: ../../modules/generated/sklearn.svm.OneClassSVM.examples:25
msgid ":ref:`example_applications_plot_outlier_detection_housing.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.OneClassSVM.examples:45
msgid ":ref:`example_applications_plot_species_distribution_modeling.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.OneClassSVM.examples:65
msgid ":ref:`example_applications_svm_gui.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.OneClassSVM.examples:85
msgid ":ref:`example_covariance_plot_outlier_detection.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.OneClassSVM.examples:105
msgid ":ref:`example_svm_plot_oneclass.py`"
msgstr ""

