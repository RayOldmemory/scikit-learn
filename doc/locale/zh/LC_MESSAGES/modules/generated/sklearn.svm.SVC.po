# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/generated/sklearn.svm.SVC.rst:2
msgid ":mod:`sklearn.svm`.SVC"
msgstr ""

#: :3
msgid "C-Support Vector Classification."
msgstr ""

#: :5
msgid ""
"The implementation is based on libsvm. The fit time complexity is more "
"than quadratic with the number of samples which makes it hard to scale to"
" dataset with more than a couple of 10000 samples."
msgstr ""

#: :9
msgid "The multiclass support is handled according to a one-vs-one scheme."
msgstr ""

#: :11
msgid ""
"For details on the precise mathematical formulation of the provided "
"kernel functions and how `gamma`, `coef0` and `degree` affect each other,"
" see the corresponding section in the narrative documentation: "
":ref:`svm_kernels`."
msgstr ""

#: :16
msgid "Read more in the :ref:`User Guide <svm_classification>`."
msgstr ""

#: :20
msgid "**C** : float, optional (default=1.0)"
msgstr ""

#: :22
msgid "Penalty parameter C of the error term."
msgstr ""

#: :24
msgid "**kernel** : string, optional (default='rbf')"
msgstr ""

#: :26
msgid ""
"Specifies the kernel type to be used in the algorithm. It must be one of "
"'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or a callable. If none "
"is given, 'rbf' will be used. If a callable is given it is used to pre-"
"compute the kernel matrix from data matrices; that matrix should be an "
"array of shape ``(n_samples, n_samples)``."
msgstr ""

#: :33
msgid "**degree** : int, optional (default=3)"
msgstr ""

#: :35
msgid ""
"Degree of the polynomial kernel function ('poly'). Ignored by all other "
"kernels."
msgstr ""

#: :38
msgid "**gamma** : float, optional (default='auto')"
msgstr ""

#: :40
msgid ""
"Kernel coefficient for 'rbf', 'poly' and 'sigmoid'. If gamma is 'auto' "
"then 1/n_features will be used instead."
msgstr ""

#: :43
msgid "**coef0** : float, optional (default=0.0)"
msgstr ""

#: :45
msgid ""
"Independent term in kernel function. It is only significant in 'poly' and"
" 'sigmoid'."
msgstr ""

#: :48
msgid "**probability** : boolean, optional (default=False)"
msgstr ""

#: :50
msgid ""
"Whether to enable probability estimates. This must be enabled prior to "
"calling `fit`, and will slow down that method."
msgstr ""

#: :53
msgid "**shrinking** : boolean, optional (default=True)"
msgstr ""

#: :55
msgid "Whether to use the shrinking heuristic."
msgstr ""

#: :57
msgid "**tol** : float, optional (default=1e-3)"
msgstr ""

#: :59
msgid "Tolerance for stopping criterion."
msgstr ""

#: :61
msgid "**cache_size** : float, optional"
msgstr ""

#: :63
msgid "Specify the size of the kernel cache (in MB)."
msgstr ""

#: :65
msgid "**class_weight** : {dict, 'balanced'}, optional"
msgstr ""

#: :67
msgid ""
"Set the parameter C of class i to class_weight[i]*C for SVC. If not "
"given, all classes are supposed to have weight one. The \"balanced\" mode"
" uses the values of y to automatically adjust weights inversely "
"proportional to class frequencies in the input data as ``n_samples / "
"(n_classes * np.bincount(y))``"
msgstr ""

#: :74
msgid "**verbose** : bool, default: False"
msgstr ""

#: :76
msgid ""
"Enable verbose output. Note that this setting takes advantage of a per-"
"process runtime setting in libsvm that, if enabled, may not work properly"
" in a multithreaded context."
msgstr ""

#: :80
msgid "**max_iter** : int, optional (default=-1)"
msgstr ""

#: :82
msgid "Hard limit on iterations within solver, or -1 for no limit."
msgstr ""

#: :84
msgid "**decision_function_shape** : 'ovo', 'ovr' or None, default=None"
msgstr ""

#: :86
msgid ""
"Whether to return a one-vs-rest ('ovr') ecision function of shape "
"(n_samples, n_classes) as all other classifiers, or the original one-vs-"
"one ('ovo') decision function of libsvm which has shape (n_samples, "
"n_classes * (n_classes - 1) / 2). The default of None will currently "
"behave as 'ovo' for backward compatibility and raise a deprecation "
"warning, but will change 'ovr' in 0.18."
msgstr ""

#: :94
msgid "*decision_function_shape='ovr'* is recommended."
msgstr ""

#: :97
msgid "Deprecated *decision_function_shape='ovo' and None*."
msgstr ""

#: :100
msgid "**random_state** : int seed, RandomState instance, or None (default)"
msgstr ""

#: :102
msgid ""
"The seed of the pseudo random number generator to use when shuffling the "
"data for probability estimation."
msgstr ""

#: :107
msgid "**support_** : array-like, shape = [n_SV]"
msgstr ""

#: :109
msgid "Indices of support vectors."
msgstr ""

#: :111
msgid "**support_vectors_** : array-like, shape = [n_SV, n_features]"
msgstr ""

#: :113
msgid "Support vectors."
msgstr ""

#: :115
msgid "**n_support_** : array-like, dtype=int32, shape = [n_class]"
msgstr ""

#: :117
msgid "Number of support vectors for each class."
msgstr ""

#: :119
msgid "**dual_coef_** : array, shape = [n_class-1, n_SV]"
msgstr ""

#: :121
msgid ""
"Coefficients of the support vector in the decision function. For "
"multiclass, coefficient for all 1-vs-1 classifiers. The layout of the "
"coefficients in the multiclass case is somewhat non-trivial. See the "
"section about multi-class classification in the SVM section of the User "
"Guide for details."
msgstr ""

#: :127
msgid "**coef_** : array, shape = [n_class-1, n_features]"
msgstr ""

#: :129
msgid ""
"Weights assigned to the features (coefficients in the primal problem). "
"This is only available in the case of a linear kernel."
msgstr ""

#: :132
msgid ""
"`coef_` is a readonly property derived from `dual_coef_` and "
"`support_vectors_`."
msgstr ""

#: :135
msgid "**intercept_** : array, shape = [n_class * (n_class-1) / 2]"
msgstr ""

#: :137
msgid "Constants in decision function."
msgstr ""

#: :142
msgid ":obj:`SVR`"
msgstr ""

#: :142
msgid "Support Vector Machine for Regression implemented using libsvm."
msgstr ""

#: :144
msgid ":obj:`LinearSVC`"
msgstr ""

#: :145
msgid ""
"Scalable Linear Support Vector Machine for classification implemented "
"using liblinear. Check the See also section of LinearSVC for more "
"comparison element."
msgstr ""

#: :148
msgid "Examples"
msgstr ""

#: :163
msgid "Methods"
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`decision_function <sklearn.svm.SVC.decision_function>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Distance of the samples X to the separating hyperplane."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`fit <sklearn.svm.SVC.fit>`\\ (X, y[, sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Fit the SVM model according to the given training data."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`get_params <sklearn.svm.SVC.get_params>`\\ ([deep])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Get parameters for this estimator."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`predict <sklearn.svm.SVC.predict>`\\ (X)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Perform classification on samples in X."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`score <sklearn.svm.SVC.score>`\\ (X, y[, sample_weight])"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Returns the mean accuracy on the given test data and labels."
msgstr ""

#: ../../<autosummary>:1
msgid ":obj:`set_params <sklearn.svm.SVC.set_params>`\\ (\\*\\*params)"
msgstr ""

#: ../../<autosummary>:1 :3
msgid "Set the parameters of this estimator."
msgstr ""

#: :7 :10
msgid "**X** : array-like, shape (n_samples, n_features)"
msgstr ""

#: :11
msgid "**X** : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)"
msgstr ""

#: :13
msgid ""
"Returns the decision function of the sample for each class in the model. "
"If decision_function_shape='ovr', the shape is (n_samples, n_classes)"
msgstr ""

#: :7 :9
msgid "**X** : {array-like, sparse matrix}, shape (n_samples, n_features)"
msgstr ""

#: :9
msgid ""
"Training vectors, where n_samples is the number of samples and n_features"
" is the number of features. For kernel=\"precomputed\", the expected "
"shape of X is (n_samples, n_samples)."
msgstr ""

#: :14
msgid "**y** : array-like, shape (n_samples,)"
msgstr ""

#: :16
msgid "Target values (class labels in classification, real numbers in regression)"
msgstr ""

#: :19
msgid "**sample_weight** : array-like, shape (n_samples,)"
msgstr ""

#: :21
msgid ""
"Per-sample weights. Rescale C per sample. Higher weights force the "
"classifier to put more emphasis on these points."
msgstr ""

#: :26
msgid "**self** : object"
msgstr ""

#: :28
msgid "Returns self."
msgstr ""

#: :31 :24
msgid "Notes"
msgstr ""

#: :32
msgid ""
"If X and y are not C-ordered and contiguous arrays of np.float64 and X is"
" not a scipy.sparse.csr_matrix, X and/or y may be copied."
msgstr ""

#: :35
msgid ""
"If X is a dense array, then the other methods will not support sparse "
"matrices as input."
msgstr ""

#: :7
msgid "**deep: boolean, optional** :"
msgstr ""

#: :9
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: :14
msgid "**params** : mapping of string to any"
msgstr ""

#: :16
msgid "Parameter names mapped to their values."
msgstr ""

#: :5
msgid "For an one-class model, +1 or -1 is returned."
msgstr ""

#: :11 :12
msgid ""
"For kernel=\"precomputed\", the expected shape of X is [n_samples_test, "
"n_samples_train]"
msgstr ""

#: :16
msgid "**y_pred** : array, shape (n_samples,)"
msgstr ""

#: :18
msgid "Class labels for samples in X."
msgstr ""

#: :3
msgid "Compute log probabilities of possible outcomes for samples in X."
msgstr ""

#: :5
msgid ""
"The model need to have probability information computed at training time:"
" fit with attribute `probability` set to True."
msgstr ""

#: :17
msgid "**T** : array-like, shape (n_samples, n_classes)"
msgstr ""

#: :19
msgid ""
"Returns the log-probabilities of the sample for each class in the model. "
"The columns correspond to the classes in sorted order, as they appear in "
"the attribute `classes_`."
msgstr ""

#: :25
msgid ""
"The probability model is created using cross validation, so the results "
"can be slightly different than those obtained by predict. Also, it will "
"produce meaningless results on very small datasets."
msgstr ""

#: :3
msgid "Compute probabilities of possible outcomes for samples in X."
msgstr ""

#: :19
msgid ""
"Returns the probability of the sample for each class in the model. The "
"columns correspond to the classes in sorted order, as they appear in the "
"attribute `classes_`."
msgstr ""

#: :5
msgid ""
"In multi-label classification, this is the subset accuracy which is a "
"harsh metric since you require for each sample that each label set be "
"correctly predicted."
msgstr ""

#: :11
msgid "**X** : array-like, shape = (n_samples, n_features)"
msgstr ""

#: :13
msgid "Test samples."
msgstr ""

#: :15
msgid "**y** : array-like, shape = (n_samples) or (n_samples, n_outputs)"
msgstr ""

#: :17
msgid "True labels for X."
msgstr ""

#: :19
msgid "**sample_weight** : array-like, shape = [n_samples], optional"
msgstr ""

#: :21
msgid "Sample weights."
msgstr ""

#: :25
msgid "**score** : float"
msgstr ""

#: :27
msgid "Mean accuracy of self.predict(X) wrt. y."
msgstr ""

#: :5
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as pipelines). The former have parameters of the form "
"``<component>__<parameter>`` so that it's possible to update each "
"component of a nested object."
msgstr ""

#: :12
msgid "**self** :"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:3
msgid "Examples using ``sklearn.svm.SVC``"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:25
msgid ":ref:`example_feature_stacker.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:45
msgid ":ref:`example_plot_multilabel.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:65
msgid ":ref:`example_hetero_feature_union.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:85
msgid ":ref:`example_plot_kernel_approximation.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:105
msgid ":ref:`example_applications_face_recognition.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:125
msgid ":ref:`example_applications_svm_gui.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:145
msgid ":ref:`example_classification_plot_digits_classification.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:165
msgid ":ref:`example_classification_plot_classification_probability.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:185
msgid ":ref:`example_classification_plot_classifier_comparison.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:205
msgid ":ref:`example_ensemble_plot_voting_decision_regions.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:225
msgid ":ref:`example_exercises_plot_cv_digits.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:245
msgid ":ref:`example_exercises_plot_iris_exercise.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:265
msgid ":ref:`example_feature_selection_feature_selection_pipeline.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:285
msgid ":ref:`example_feature_selection_plot_rfe_digits.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:305
msgid ":ref:`example_feature_selection_plot_rfe_with_cross_validation.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:325
msgid ":ref:`example_feature_selection_plot_permutation_test_for_classification.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:345
msgid ":ref:`example_feature_selection_plot_feature_selection.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:365
msgid ":ref:`example_model_selection_plot_validation_curve.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:385
msgid ":ref:`example_model_selection_plot_confusion_matrix.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:405
msgid ":ref:`example_model_selection_plot_roc_crossval.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:425
msgid ":ref:`example_model_selection_grid_search_digits.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:445
msgid ":ref:`example_model_selection_plot_precision_recall.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:465
msgid ":ref:`example_model_selection_plot_learning_curve.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:485
msgid ":ref:`example_model_selection_plot_roc.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:505
msgid ":ref:`example_semi_supervised_plot_label_propagation_versus_svm_iris.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:525
msgid ":ref:`example_svm_plot_separating_hyperplane.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:545
msgid ":ref:`example_svm_plot_separating_hyperplane_unbalanced.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:565
msgid ":ref:`example_svm_plot_custom_kernel.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:585
msgid ":ref:`example_svm_plot_svm_anova.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:605
msgid ":ref:`example_svm_plot_weighted_samples.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:625
msgid ":ref:`example_svm_plot_iris.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:645
msgid ":ref:`example_svm_plot_svm_kernels.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:665
msgid ":ref:`example_svm_plot_svm_margin.py`"
msgstr ""

#: ../../modules/generated/sklearn.svm.SVC.examples:685
msgid ":ref:`example_svm_plot_rbf_parameters.py`"
msgstr ""

