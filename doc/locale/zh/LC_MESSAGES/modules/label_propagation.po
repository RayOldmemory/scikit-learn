# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/label_propagation.rst:5
msgid "Semi-Supervised"
msgstr ""

#: ../../modules/label_propagation.rst:9
msgid ""
"`Semi-supervised learning <http://en.wikipedia.org/wiki/Semi-"
"supervised_learning>`_ is a situation in which in your training data some"
" of the samples are not labeled. The semi-supervised estimators in "
":mod:`sklearn.semi_supervised` are able to make use of this additional "
"unlabeled data to better capture the shape of the underlying data "
"distribution and generalize better to new samples. These algorithms can "
"perform well when we have a very small amount of labeled points and a "
"large amount of unlabeled points."
msgstr ""

#: ../../modules/label_propagation.rst
msgid "Unlabeled entries in `y`"
msgstr ""

#: ../../modules/label_propagation.rst:20
msgid ""
"It is important to assign an identifier to unlabeled points along with "
"the labeled data when training the model with the ``fit`` method. The "
"identifier that this implementation uses is the integer value :math:`-1`."
msgstr ""

#: ../../modules/label_propagation.rst:27
msgid "Label Propagation"
msgstr ""

#: ../../modules/label_propagation.rst:29
msgid ""
"Label propagation denotes a few variations of semi-supervised graph "
"inference algorithms."
msgstr ""

#: ../../modules/label_propagation.rst:34
msgid "A few features available in this model:"
msgstr ""

#: ../../modules/label_propagation.rst:33
msgid "Can be used for classification and regression tasks"
msgstr ""

#: ../../modules/label_propagation.rst:34
msgid "Kernel methods to project data into alternate dimensional spaces"
msgstr ""

#: ../../modules/label_propagation.rst:36
msgid ""
"`scikit-learn` provides two label propagation models: "
":class:`LabelPropagation` and :class:`LabelSpreading`. Both work by "
"constructing a similarity graph over all items in the input dataset."
msgstr ""

#: ../../modules/label_propagation.rst:45
msgid ""
"**An illustration of label-propagation:** *the structure of unlabeled "
"observations is consistent with the class structure, and thus the class "
"label can be propagated to the unlabeled observations of the training "
"set.*"
msgstr ""

#: ../../modules/label_propagation.rst:50
msgid ""
":class:`LabelPropagation` and :class:`LabelSpreading` differ in "
"modifications to the similarity matrix that graph and the clamping effect"
" on the label distributions. Clamping allows the algorithm to change the "
"weight of the true ground labeled data to some degree. The "
":class:`LabelPropagation` algorithm performs hard clamping of input "
"labels, which means :math:`\\alpha=1`. This clamping factor can be "
"relaxed, to say :math:`\\alpha=0.8`, which means that we will always "
"retain 80 percent of our original label distribution, but the algorithm "
"gets to change it's confidence of the distribution within 20 percent."
msgstr ""

#: ../../modules/label_propagation.rst:60
msgid ""
":class:`LabelPropagation` uses the raw similarity matrix constructed from"
" the data with no modifications. In contrast, :class:`LabelSpreading` "
"minimizes a loss function that has regularization properties, as such it "
"is often more robust to noise. The algorithm iterates on a modified "
"version of the original graph and normalizes the edge weights by "
"computing the normalized graph Laplacian matrix. This procedure is also "
"used in :ref:`spectral_clustering`."
msgstr ""

#: ../../modules/label_propagation.rst:68
msgid ""
"Label propagation models have two built-in kernel methods. Choice of "
"kernel effects both scalability and performance of the algorithms. The "
"following are available:"
msgstr ""

#: ../../modules/label_propagation.rst:72
msgid ""
"rbf (:math:`\\exp(-\\gamma |x-y|^2), \\gamma > 0`). :math:`\\gamma` is "
"specified by keyword gamma."
msgstr ""

#: ../../modules/label_propagation.rst:75
msgid ""
"knn (:math:`1[x' \\in kNN(x)]`). :math:`k` is specified by keyword "
"n_neighbors."
msgstr ""

#: ../../modules/label_propagation.rst:78
msgid ""
"The RBF kernel will produce a fully connected graph which is represented "
"in memory by a dense matrix. This matrix may be very large and combined "
"with the cost of performing a full matrix multiplication calculation for "
"each iteration of the algorithm can lead to prohibitively long running "
"times. On the other hand, the KNN kernel will produce a much more memory-"
"friendly sparse matrix which can drastically reduce running times."
msgstr ""

#: ../../modules/label_propagation.rst
msgid "Examples"
msgstr ""

#: ../../modules/label_propagation.rst:87
msgid ":ref:`example_semi_supervised_plot_label_propagation_versus_svm_iris.py`"
msgstr ""

#: ../../modules/label_propagation.rst:88
msgid ":ref:`example_semi_supervised_plot_label_propagation_structure.py`"
msgstr ""

#: ../../modules/label_propagation.rst:89
msgid ":ref:`example_semi_supervised_plot_label_propagation_digits_active_learning.py`"
msgstr ""

#: ../../modules/label_propagation.rst
msgid "References"
msgstr ""

#: ../../modules/label_propagation.rst:93
msgid ""
"[1] Yoshua Bengio, Olivier Delalleau, Nicolas Le Roux. In Semi-Supervised"
" Learning (2006), pp. 193-216"
msgstr ""

#: ../../modules/label_propagation.rst:96
msgid ""
"[2] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Efficient Non-"
"Parametric Function Induction in Semi-Supervised Learning. AISTAT 2005 "
"http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf"
msgstr ""

