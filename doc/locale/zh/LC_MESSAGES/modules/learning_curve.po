# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../modules/learning_curve.rst:5
msgid "Validation curves: plotting scores to evaluate models"
msgstr ""

#: ../../modules/learning_curve.rst:9
msgid ""
"Every estimator has its advantages and drawbacks. Its generalization "
"error can be decomposed in terms of bias, variance and noise. The "
"**bias** of an estimator is its average error for different training "
"sets. The **variance** of an estimator indicates how sensitive it is to "
"varying training sets. Noise is a property of the data."
msgstr ""

#: ../../modules/learning_curve.rst:15
msgid ""
"In the following plot, we see a function :math:`f(x) = \\cos "
"(\\frac{3}{2} \\pi x)` and some noisy samples from that function. We use "
"three different estimators to fit the function: linear regression with "
"polynomial features of degree 1, 4 and 15. We see that the first "
"estimator can at best provide only a poor fit to the samples and the true"
" function because it is too simple (high bias), the second estimator "
"approximates it almost perfectly and the last estimator approximates the "
"training data perfectly but does not fit the true function very well, "
"i.e. it is very sensitive to varying training data (high variance)."
msgstr ""

#: ../../modules/learning_curve.rst:29
msgid ""
"Bias and variance are inherent properties of estimators and we usually "
"have to select learning algorithms and hyperparameters so that both bias "
"and variance are as low as possible (see `Bias-variance dilemma "
"<http://en.wikipedia.org/wiki/Bias-variance_dilemma>`_). Another way to "
"reduce the variance of a model is to use more training data. However, you"
" should only collect more training data if the true function is too "
"complex to be approximated by an estimator with a lower variance."
msgstr ""

#: ../../modules/learning_curve.rst:37
msgid ""
"In the simple one-dimensional problem that we have seen in the example it"
" is easy to see whether the estimator suffers from bias or variance. "
"However, in high-dimensional spaces, models can become very difficult to "
"visualize. For this reason, it is often helpful to use the tools "
"described below."
msgstr ""

#: ../../modules/learning_curve.rst
msgid "Examples:"
msgstr ""

#: ../../modules/learning_curve.rst:44
msgid ":ref:`example_model_selection_plot_underfitting_overfitting.py`"
msgstr ""

#: ../../modules/learning_curve.rst:45
msgid ":ref:`example_model_selection_plot_validation_curve.py`"
msgstr ""

#: ../../modules/learning_curve.rst:46
msgid ":ref:`example_model_selection_plot_learning_curve.py`"
msgstr ""

#: ../../modules/learning_curve.rst:52
msgid "Validation curve"
msgstr ""

#: ../../modules/learning_curve.rst:54
msgid ""
"To validate a model we need a scoring function (see "
":ref:`model_evaluation`), for example accuracy for classifiers. The "
"proper way of choosing multiple hyperparameters of an estimator are of "
"course grid search or similar methods (see :ref:`grid_search`) that "
"select the hyperparameter with the maximum score on a validation set or "
"multiple validation sets. Note that if we optimized the hyperparameters "
"based on a validation score the validation score is biased and not a good"
" estimate of the generalization any longer. To get a proper estimate of "
"the generalization we have to compute the score on another test set."
msgstr ""

#: ../../modules/learning_curve.rst:64
msgid ""
"However, it is sometimes helpful to plot the influence of a single "
"hyperparameter on the training score and the validation score to find out"
" whether the estimator is overfitting or underfitting for some "
"hyperparameter values."
msgstr ""

#: ../../modules/learning_curve.rst:69
msgid "The function :func:`validation_curve` can help in this case::"
msgstr ""

#: ../../modules/learning_curve.rst:94
msgid ""
"If the training score and the validation score are both low, the "
"estimator will be underfitting. If the training score is high and the "
"validation score is low, the estimator is overfitting and otherwise it is"
" working very well. A low training score and a high validation score is "
"usually not possible. All three cases can be found in the plot below "
"where we vary the parameter :math:`\\gamma` of an SVM on the digits "
"dataset."
msgstr ""

#: ../../modules/learning_curve.rst:110
msgid "Learning curve"
msgstr ""

#: ../../modules/learning_curve.rst:112
msgid ""
"A learning curve shows the validation and training score of an estimator "
"for varying numbers of training samples. It is a tool to find out how "
"much we benefit from adding more training data and whether the estimator "
"suffers more from a variance error or a bias error. If both the "
"validation score and the training score converge to a value that is too "
"low with increasing size of the training set, we will not benefit much "
"from more training data. In the following plot you can see an example: "
"naive Bayes roughly converges to a low score."
msgstr ""

#: ../../modules/learning_curve.rst:126
msgid ""
"We will probably have to use an estimator or a parametrization of the "
"current estimator that can learn more complex concepts (i.e. has a lower "
"bias). If the training score is much greater than the validation score "
"for the maximum number of training samples, adding more training samples "
"will most likely increase generalization. In the following plot you can "
"see that the SVM could benefit from more training examples."
msgstr ""

#: ../../modules/learning_curve.rst:138
msgid ""
"We can use the function :func:`learning_curve` to generate the values "
"that are required to plot such a learning curve (number of samples that "
"have been used, the average scores on the training sets and the average "
"scores on the validation sets)::"
msgstr ""

