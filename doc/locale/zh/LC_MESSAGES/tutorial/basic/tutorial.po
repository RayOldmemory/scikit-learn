# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2010 - 2014, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.17\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-02-16 21:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.2.0\n"

#: ../../tutorial/basic/tutorial.rst:4
msgid "An introduction to machine learning with scikit-learn"
msgstr ""

#: ../../tutorial/basic/tutorial.rst
msgid "Section contents"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:8
msgid ""
"In this section, we introduce the `machine learning "
"<http://en.wikipedia.org/wiki/Machine_learning>`_ vocabulary that we use "
"throughout scikit-learn and give a simple learning example."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:15
msgid "Machine learning: the problem setting"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:17
msgid ""
"In general, a learning problem considers a set of n `samples "
"<http://en.wikipedia.org/wiki/Sample_(statistics)>`_ of data and then "
"tries to predict properties of unknown data. If each sample is more than "
"a single number and, for instance, a multi-dimensional entry (aka "
"`multivariate "
"<http://en.wikipedia.org/wiki/Multivariate_random_variable>`_ data), is "
"it said to have several attributes or **features**."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:24
msgid "We can separate learning problems in a few large categories:"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:26
msgid ""
"`supervised learning "
"<http://en.wikipedia.org/wiki/Supervised_learning>`_, in which the data "
"comes with additional attributes that we want to predict (:ref:`Click "
"here <supervised-learning>` to go to the scikit-learn supervised learning"
" page).This problem can be either:"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:32
msgid ""
"`classification "
"<http://en.wikipedia.org/wiki/Classification_in_machine_learning>`_: "
"samples belong to two or more classes and we want to learn from already "
"labeled data how to predict the class of unlabeled data. An example of "
"classification problem would be the handwritten digit recognition "
"example, in which the aim is to assign each input vector to one of a "
"finite number of discrete categories.  Another way to think of "
"classification is as a discrete (as opposed to continuous) form of "
"supervised learning where one has a limited number of categories and for "
"each of the n samples provided, one is to try to label them with the "
"correct category or class."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:44
msgid ""
"`regression <http://en.wikipedia.org/wiki/Regression_analysis>`_: if the "
"desired output consists of one or more continuous variables, then the "
"task is called *regression*. An example of a regression problem would be "
"the prediction of the length of a salmon as a function of its age and "
"weight."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:50
msgid ""
"`unsupervised learning "
"<http://en.wikipedia.org/wiki/Unsupervised_learning>`_, in which the "
"training data consists of a set of input vectors x without any "
"corresponding target values. The goal in such problems may be to discover"
" groups of similar examples within the data, where it is called "
"`clustering <http://en.wikipedia.org/wiki/Cluster_analysis>`_, or to "
"determine the distribution of data within the input space, known as "
"`density estimation <http://en.wikipedia.org/wiki/Density_estimation>`_, "
"or to project the data from a high-dimensional space down to two or three"
" dimensions for the purpose of *visualization* (:ref:`Click here "
"<unsupervised-learning>` to go to the Scikit-Learn unsupervised learning "
"page)."
msgstr ""

#: ../../tutorial/basic/tutorial.rst
msgid "Training set and testing set"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:64
msgid ""
"Machine learning is about learning some properties of a data set and "
"applying them to new data. This is why a common practice in machine "
"learning to evaluate an algorithm is to split the data at hand into two "
"sets, one that we call the **training set** on which we learn data "
"properties and one that we call the **testing set** on which we test "
"these properties."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:74
msgid "Loading an example dataset"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:76
msgid ""
"`scikit-learn` comes with a few standard datasets, for instance the `iris"
" <http://en.wikipedia.org/wiki/Iris_flower_data_set>`_ and `digits "
"<http://archive.ics.uci.edu/ml/datasets/Pen-"
"Based+Recognition+of+Handwritten+Digits>`_ datasets for classification "
"and the `boston house prices dataset "
"<http://archive.ics.uci.edu/ml/datasets/Housing>`_ for regression."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:82
msgid ""
"In the following, we start a Python interpreter from our shell and then "
"load the ``iris`` and ``digits`` datasets.  Our notational convention is "
"that ``$`` denotes the shell prompt while ``>>>`` denotes the Python "
"interpreter prompt::"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:92
msgid ""
"A dataset is a dictionary-like object that holds all the data and some "
"metadata about the data. This data is stored in the ``.data`` member, "
"which is a ``n_samples, n_features`` array. In the case of supervised "
"problem, one or more response variables are stored in the ``.target`` "
"member. More details on the different datasets can be found in the "
":ref:`dedicated section <datasets>`."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:99
msgid ""
"For instance, in the case of the digits dataset, ``digits.data`` gives "
"access to the features that can be used to classify the digits samples::"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:111
msgid ""
"and ``digits.target`` gives the ground truth for the digit dataset, that "
"is the number corresponding to each digit image that we are trying to "
"learn::"
msgstr ""

#: ../../tutorial/basic/tutorial.rst
msgid "Shape of the data arrays"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:120
msgid ""
"The data is always a 2D array, shape ``(n_samples, n_features)``, "
"although the original data may have had a different shape. In the case of"
" the digits, each original sample is an image of shape ``(8, 8)`` and can"
" be accessed using::"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:135
msgid ""
"The :ref:`simple example on this dataset "
"<example_classification_plot_digits_classification.py>` illustrates how "
"starting from the original problem one can shape the data for consumption"
" in scikit-learn."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:142
msgid "Learning and predicting"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:144
msgid ""
"In the case of the digits dataset, the task is to predict, given an "
"image, which digit it represents. We are given samples of each of the 10 "
"possible classes (the digits zero through nine) on which we *fit* an "
"`estimator <http://en.wikipedia.org/wiki/Estimator>`_ to be able to "
"*predict* the classes to which unseen samples belong."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:150
msgid ""
"In scikit-learn, an estimator for classification is a Python object that "
"implements the methods ``fit(X, y)`` and ``predict(T)``."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:153
msgid ""
"An example of an estimator is the class ``sklearn.svm.SVC`` that "
"implements `support vector classification "
"<http://en.wikipedia.org/wiki/Support_vector_machine>`_. The constructor "
"of an estimator takes as arguments the parameters of the model, but for "
"the time being, we will consider the estimator as a black box::"
msgstr ""

#: ../../tutorial/basic/tutorial.rst
msgid "Choosing the parameters of the model"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:165
msgid ""
"In this example we set the value of ``gamma`` manually. It is possible to"
" automatically find good values for the parameters by using tools such as"
" :ref:`grid search <grid_search>` and :ref:`cross validation "
"<cross_validation>`."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:170
msgid ""
"We call our estimator instance ``clf``, as it is a classifier. It now "
"must be fitted to the model, that is, it must *learn* from the model. "
"This is done by passing our training set to the ``fit`` method. As a "
"training set, let us use all the images of our dataset apart from the "
"last one. We select this training set with the ``[:-1]`` Python syntax, "
"which produces a new array that contains all but the last entry of "
"``digits.data``::"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:184
msgid ""
"Now you can predict new values, in particular, we can ask to the "
"classifier what is the digit of our last image in the ``digits`` dataset,"
" which we have not used to train the classifier::"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:191
msgid "The corresponding image is the following:"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:198
msgid ""
"As you can see, it is a challenging task: the images are of poor "
"resolution. Do you agree with the classifier?"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:201
msgid ""
"A complete example of this classification problem is available as an "
"example that you can run and study: "
":ref:`example_classification_plot_digits_classification.py`."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:207
msgid "Model persistence"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:209
msgid ""
"It is possible to save a model in the scikit by using Python's built-in "
"persistence model, namely `pickle "
"<http://docs.python.org/library/pickle.html>`_::"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:231
msgid ""
"In the specific case of the scikit, it may be more interesting to use "
"joblib's replacement of pickle (``joblib.dump`` & ``joblib.load``), which"
" is more efficient on big data, but can only pickle to the disk and not "
"to a string::"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:239
msgid ""
"Later you can load back the pickled model (possibly in another Python "
"process) with::"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:246
msgid ""
"joblib.dump returns a list of filenames. Each individual numpy array "
"contained in the ``clf`` object is serialized as a separate file on the "
"filesystem. All files are required in the same folder when reloading the "
"model with joblib.load."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:251
msgid ""
"Note that pickle has some security and maintainability issues. Please "
"refer to section :ref:`model_persistence` for more detailed information "
"about model persistence with scikit-learn."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:257
msgid "Conventions"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:259
msgid ""
"scikit-learn estimators follow certain rules to make their behavior more "
"predictive."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:264
msgid "Type casting"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:266
msgid "Unless otherwise specified, input will be cast to ``float64``::"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:282
msgid ""
"In this example, ``X`` is ``float32``, which is cast to ``float64`` by "
"``fit_transform(X)``."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:285
msgid ""
"Regression targets are cast to ``float64``, classification targets are "
"maintained::"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:310
msgid ""
"Here, the first ``predict()`` returns an integer array, since "
"``iris.target`` (an integer array) was used in ``fit``. The second "
"``predict`` returns a string array, since ``iris.target_names`` was for "
"fitting."
msgstr ""

#: ../../tutorial/basic/tutorial.rst:316
msgid "Refitting and updating parameters"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:318
msgid ""
"Hyper-parameters of an estimator can be updated after it has been "
"constructed via the :func:`sklearn.pipeline.Pipeline.set_params` method. "
"Calling ``fit()`` more than once will overwrite what was learned by any "
"previous ``fit()``::"
msgstr ""

#: ../../tutorial/basic/tutorial.rst:347
msgid ""
"Here, the default kernel ``rbf`` is first changed to ``linear`` after the"
" estimator has been constructed via ``SVC()``, and changed back to "
"``rbf`` to refit the estimator and to make a second prediction."
msgstr ""

